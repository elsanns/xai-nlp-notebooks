{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "electra_fine_tune_explain_captum_ig.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Qi5nKLqupSt_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0b21a80ae0e444ca31ad76cb1052477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c740942a2ed745e0acc318412901b97a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43eeceb39a45475bbf57b5ec0140f938",
              "IPY_MODEL_2aaa303766d1404192706b4f941593ed"
            ]
          }
        },
        "c740942a2ed745e0acc318412901b97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43eeceb39a45475bbf57b5ec0140f938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e110069213fa4017a02b9d8e3d551837",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa89f1ecd2ab4e5caf5f7e3ef7d28367"
          }
        },
        "2aaa303766d1404192706b4f941593ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a280dede46d047caa06bfba3e264aaa4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [19:10&lt;00:00, 383.36s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3adc581868704b35bb8bd757ab205bb3"
          }
        },
        "e110069213fa4017a02b9d8e3d551837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa89f1ecd2ab4e5caf5f7e3ef7d28367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a280dede46d047caa06bfba3e264aaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3adc581868704b35bb8bd757ab205bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f0c6edbb64743808f15db19448291a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da1bad36eeb24eab96ad3cb21664da68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d513e8c7a51c49ff8366a309b1676236",
              "IPY_MODEL_b9d94af9a8ba4df3948efffecf7ddf19"
            ]
          }
        },
        "da1bad36eeb24eab96ad3cb21664da68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d513e8c7a51c49ff8366a309b1676236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c92c44b7c09d4027a0bd6bdb19c34e8c",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2104,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2104,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b293a6481a3844d9822a7a032e02f451"
          }
        },
        "b9d94af9a8ba4df3948efffecf7ddf19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea0e04ff5acf4f78946c3bb05bf11014",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2104/2104 [06:24&lt;00:00,  5.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_196abf04ef9c40ae86e63e630ae20f9e"
          }
        },
        "c92c44b7c09d4027a0bd6bdb19c34e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b293a6481a3844d9822a7a032e02f451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea0e04ff5acf4f78946c3bb05bf11014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "196abf04ef9c40ae86e63e630ae20f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acd3de89dfd0467b84f425b6d241f931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c8caeaab8314495ab71515cd29a0347",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_513a4a45e8f940c9acdaa3bd30dd0c4e",
              "IPY_MODEL_ecdfc241612f41528f7a056642c0d74d"
            ]
          }
        },
        "4c8caeaab8314495ab71515cd29a0347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "513a4a45e8f940c9acdaa3bd30dd0c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e43a0a3d8334097a777f84ffd1a6d71",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2104,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2104,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d2c5b55fd1f471f876f939f28205f13"
          }
        },
        "ecdfc241612f41528f7a056642c0d74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f314ff35bca4f6f8bb18a0aa302110f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2104/2104 [06:23&lt;00:00,  5.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3347c9d0ec724ce3bcef495b8a17e621"
          }
        },
        "1e43a0a3d8334097a777f84ffd1a6d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d2c5b55fd1f471f876f939f28205f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f314ff35bca4f6f8bb18a0aa302110f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3347c9d0ec724ce3bcef495b8a17e621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5021ee5fa3fa429ebe2d85410f51b7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_699499f9801e4fb7967f524e9f8be9a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af3da674edd747c1b2effa7e026b9890",
              "IPY_MODEL_6aadc754589c4dc08846b2ecf6eec005"
            ]
          }
        },
        "699499f9801e4fb7967f524e9f8be9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af3da674edd747c1b2effa7e026b9890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1872b65d1e024352baec24185aafd6fd",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2104,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2104,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3add776221b6476ea5200a079532a8f5"
          }
        },
        "6aadc754589c4dc08846b2ecf6eec005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b8c44c65f5a472d9c56cc38cf5f86e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2104/2104 [06:22&lt;00:00,  5.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb6f1d6f55644628803d02f431d79623"
          }
        },
        "1872b65d1e024352baec24185aafd6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3add776221b6476ea5200a079532a8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b8c44c65f5a472d9c56cc38cf5f86e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb6f1d6f55644628803d02f431d79623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8f6bf79b9a84c3c98a2675756c7c11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a4a19eecb73432d8b933792b070dd89",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3817dbd4d0eb46499ce3cdf1560e7cab",
              "IPY_MODEL_8563c739a3ee4f0995e9507422852533"
            ]
          }
        },
        "5a4a19eecb73432d8b933792b070dd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3817dbd4d0eb46499ce3cdf1560e7cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8ef8833f8db4ba088190e1e86babab9",
            "_dom_classes": [],
            "description": "Evaluation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1e25aa6612d4d29b027479df04a2d84"
          }
        },
        "8563c739a3ee4f0995e9507422852533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f45bef924c64a5eb0ed4e0b6e45ee29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 109/109 [00:31&lt;00:00,  3.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f7ce8a37be8401099e6ecf4bbfb86e5"
          }
        },
        "a8ef8833f8db4ba088190e1e86babab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1e25aa6612d4d29b027479df04a2d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f45bef924c64a5eb0ed4e0b6e45ee29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f7ce8a37be8401099e6ecf4bbfb86e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e6a82f7e38145529a64db841bbca7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbd634f3fbd74387a04056c00b756fc4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b058709915540e0ae1fa23dbb5d35b6",
              "IPY_MODEL_851bafaffba1473180428eefdd559077"
            ]
          }
        },
        "cbd634f3fbd74387a04056c00b756fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b058709915540e0ae1fa23dbb5d35b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4dbe2849168d446e99e68413c2e2d8f8",
            "_dom_classes": [],
            "description": "Prediction: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a70ad77b79234d67b54326be02bf7e25"
          }
        },
        "851bafaffba1473180428eefdd559077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7dc281ce77b94480a4977f196b014309",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 109/109 [00:02&lt;00:00, 50.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fb48980e51546c98aa34d51f496e4b1"
          }
        },
        "4dbe2849168d446e99e68413c2e2d8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a70ad77b79234d67b54326be02bf7e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dc281ce77b94480a4977f196b014309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fb48980e51546c98aa34d51f496e4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FD5B2B7Kq-V",
        "colab_type": "text"
      },
      "source": [
        "[GitHub](https://github.com/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_explain_captum_ig.ipynb)\n",
        "\n",
        "# Content\n",
        "---\n",
        "\n",
        "\n",
        "This notebook contains an example of [fine-tuning](https://huggingface.co/transformers/training.html) an [Electra](https://huggingface.co/transformers/model_doc/electra.html) model on the [GLUE SST-2](https://nlp.stanford.edu/sentiment/index.html) dataset. After fine-tuning, the [Integrated Gradients](https://arxiv.org/pdf/1703.01365.pdf) **interpretability** method is applied to compute tokens' attributions for each target class. \n",
        "* We will instantiate a pre-trained Electra model from the [Transformers](https://huggingface.co/transformers/) library. \n",
        "* The data is downloaded from the [nlp](https://huggingface.co/nlp/) library. The input text is tokenized with [ElectraTokenizerFast](https://huggingface.co/transformers/model_doc/electra.html#electratokenizerfast) tokenizer backed by HF [tokenizers](https://huggingface.co/transformers/main_classes/tokenizer.html) library.\n",
        "* **Fine-tuning** for sentiment analysis is handled by the [Trainer](https://huggingface.co/transformers/main_classes/trainer.html) class. \n",
        "* After fine-tuning, the [Integrated Gradients](https://captum.ai/api/integrated_gradients.html) interpretability algorithm will assign importance scores to\n",
        "input tokens. We will use a **PyTorch** implementation from the [Captum](https://captum.ai/) library. \n",
        "  - The algorithm requires providing a reference sample (a baseline) since importance attribution is performed based on the model's output, as inputs change from reference values to the actual sample. \n",
        "  - The Integrated Gradients method satisfies the [completeness](http://theory.stanford.edu/~ataly/Talks/sri_attribution_talk_jun_2017.pdf) property. We will look at the sum of attributions for a sample and show that the sum approximates (explains) prediction's shift from the baseline value. \n",
        "* The final sections of this notebook contain a colour-coded **visualization** of attribution results made with *captum.attr.visualization* library.\n",
        "\n",
        "The notebook is based on the [Hugging Face documentation](https://huggingface.co/) and the implementation of Integrated Gradients attribution methods is adapted from the Captum.ai\n",
        "[Interpreting BERT Models (Part 1)](https://captum.ai/tutorials/Bert_SQUAD_Interpret)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi5nKLqupSt_",
        "colab_type": "text"
      },
      "source": [
        "# Installation & imports\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n23Rko2YVSLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "87be1cd2-eda3-4291-a1af-ab463f88d360"
      },
      "source": [
        "!pip install transformers\n",
        "# pyarrow version as required by nlp v 0.3.0 (runtime restart in Colab)\n",
        "!pip install \"pyarrow==0.16.0\"  \n",
        "!pip install nlp\n",
        "!pip install captum"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: pyarrow==0.16.0 in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.16.0) (1.18.5)\n",
            "Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.5)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.16.0->nlp) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from captum) (1.6.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from captum) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->captum) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FctqAnsgVcQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "52feda76-ec77-4d30-e722-1d40e518b368"
      },
      "source": [
        "from typing import Dict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from captum.attr import (IntegratedGradients, LayerIntegratedGradients,\n",
        "                         configure_interpretable_embedding_layer,\n",
        "                         remove_interpretable_embedding_layer)\n",
        "from captum.attr import visualization as viz\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (ElectraForSequenceClassification,\n",
        "                          ElectraTokenizerFast, EvalPrediction, InputFeatures,\n",
        "                          Trainer, TrainingArguments, glue_compute_metrics)\n",
        "\n",
        "transformers.__version__"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.0.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHa2VomPVf9r",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3po0cgEvypP",
        "colab_type": "text"
      },
      "source": [
        "Sentiment analysis is a classification task that requires assigning a label to an entire sentence (sequence). We will use a PyTorch implementation of [ElectraForSequenceClassification](https://huggingface.co/transformers/model_doc/electra.html#electraforsequenceclassification) from the Hugging Face library. A matching tokenizer implemented in the [ElectraTokenizerFast](https://huggingface.co/transformers/model_doc/electra.html#electratokenizerfast) class will handle tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TioBrt5VhIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "00944934-f215-44c7-8793-0f5af3c84ebb"
      },
      "source": [
        "model = ElectraForSequenceClassification.from_pretrained(\n",
        "    \"google/electra-small-discriminator\", num_labels = 2)\n",
        "\n",
        "tokenizer = ElectraTokenizerFast.from_pretrained(\n",
        "    \"google/electra-small-discriminator\", do_lower_case=True)                      "
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SdUQg2ntJYj",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--54_ugqalQb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Download**\n",
        "\n",
        "Let's now download the SST-2 dataset from the nlp library and take a brief look at it. It contains short movie reviews labelled for sentiment: 0 for negative and 1 for a positive review. The data is split into training, validation and test set. The labels for the test set are kept undisclosed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEn6pshAVkmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "9b72eea7-5dcf-4731-a6a9-90e8632dd17a"
      },
      "source": [
        "# Load the SST2 dataset from the nlp library\n",
        "dataset = nlp.load_dataset('glue', 'sst2')\n",
        "\n",
        "# Look at the labels\n",
        "print(\"Training set labels: {}\".format(set(dataset['train']['label'])))\n",
        "print(\"Validation set labels: {}\".format(set(dataset['validation']['label'])))\n",
        "print(\"Test set labels: {}\".format(set(dataset['test']['label'])))\n",
        "\n",
        "# Explore the dataset\n",
        "df = pd.DataFrame({\"senence\": dataset[\"train\"][\"sentence\"],\n",
        "                   \"label\": dataset[\"train\"][\"label\"]})\n",
        "pd.options.display.max_colwidth = 0\n",
        "df.head()"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set labels: {0, 1}\n",
            "Validation set labels: {0, 1}\n",
            "Test set labels: {-1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>senence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates something rather beautiful about human nature</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>remains utterly satisfied to remain the same throughout</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>on the worst revenge-of-the-nerds clichés the filmmakers could dredge up</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                     senence  label\n",
              "0  hide new secretions from the parental units                                                0    \n",
              "1  contains no wit , only labored gags                                                        0    \n",
              "2  that loves its characters and communicates something rather beautiful about human nature   1    \n",
              "3  remains utterly satisfied to remain the same throughout                                    0    \n",
              "4  on the worst revenge-of-the-nerds clichés the filmmakers could dredge up                   0    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E-1tg1jyAjJ",
        "colab_type": "text"
      },
      "source": [
        "**Create dataset**\n",
        "\n",
        "We will now create a custom [map-style PyTorch dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets) to serve model's key-value parameters in a seamless manner. \n",
        "\n",
        "The TrainerDataset class is derived from *torch.utils.data.Dataset*. The overridden *\\__getitem\\__* method yields a Python *Object* \n",
        "for compatibility with the [DefaultDataCollator](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py), in this example, the InputFeatures class is used. \n",
        "\n",
        "Conversion to torch tensors and placing on cuda/cpu is handled by the Trainer object used for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg9gClv2VtGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainerDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Tokenize the input\n",
        "        self.tokenized_inputs = tokenizer(inputs, padding=True)   \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return InputFeatures(\n",
        "            input_ids=self.tokenized_inputs['input_ids'][idx],\n",
        "            token_type_ids=self.tokenized_inputs['token_type_ids'][idx],\n",
        "            attention_mask=self.tokenized_inputs['attention_mask'][idx],\n",
        "            label=self.targets[idx])         "
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ncdro4DEcf4",
        "colab_type": "text"
      },
      "source": [
        "We need to create the training and validation datasets. As GLUE SST-2 dataset does not disclose labels for the test set, we will be using validation data for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIjHu-eMVu3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TrainerDataset(dataset[\"train\"][\"sentence\"],\n",
        "                               dataset[\"train\"][\"label\"], tokenizer)\n",
        "eval_dataset = TrainerDataset(dataset[\"validation\"][\"sentence\"],\n",
        "                              dataset[\"validation\"][\"label\"], tokenizer)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hki37gxJVxTX",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK6lfc6Hidmt",
        "colab_type": "text"
      },
      "source": [
        "Fine-tuning with a Trainer class instance requires setting training arguments and creating a trainer object. The model, as well as training and validation datasets, are passed to the trainer's constructor, along with training arguments. The trainer class takes care of conversion to tensor format and placement on a cpu/gpu device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRZJsqMRwixQ",
        "colab_type": "text"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0F-0xBBwoSO",
        "colab_type": "text"
      },
      "source": [
        "Training parameters have been taken from the [Electra Github](https://github.com/google-research/electra/blob/master/configure_finetuning.py) repository or are default values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2aR1A8LVzLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./models/model_electra\",\n",
        "    num_train_epochs=3,\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    per_device_train_batch_size=32,\n",
        "    dataloader_drop_last=True,  # Make sure all batches are of equal size\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction) -> Dict:\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    # The choice of a dataset (task_name) implies metric\n",
        "    return glue_compute_metrics(\n",
        "        task_name=\"sst-2\",\n",
        "        preds=preds,\n",
        "        labels=p.label_ids)\n",
        "\n",
        "\n",
        "# Instantiane the Trainer class\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXTyBstWV1LM",
        "colab_type": "text"
      },
      "source": [
        "## Run fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr9UZ4PqiHo0",
        "colab_type": "text"
      },
      "source": [
        "Run the `train` method of the trainer object to fine-tune the model on the SST-2 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lVhSg4IV23Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "a0b21a80ae0e444ca31ad76cb1052477",
            "c740942a2ed745e0acc318412901b97a",
            "43eeceb39a45475bbf57b5ec0140f938",
            "2aaa303766d1404192706b4f941593ed",
            "e110069213fa4017a02b9d8e3d551837",
            "aa89f1ecd2ab4e5caf5f7e3ef7d28367",
            "a280dede46d047caa06bfba3e264aaa4",
            "3adc581868704b35bb8bd757ab205bb3",
            "2f0c6edbb64743808f15db19448291a4",
            "da1bad36eeb24eab96ad3cb21664da68",
            "d513e8c7a51c49ff8366a309b1676236",
            "b9d94af9a8ba4df3948efffecf7ddf19",
            "c92c44b7c09d4027a0bd6bdb19c34e8c",
            "b293a6481a3844d9822a7a032e02f451",
            "ea0e04ff5acf4f78946c3bb05bf11014",
            "196abf04ef9c40ae86e63e630ae20f9e",
            "acd3de89dfd0467b84f425b6d241f931",
            "4c8caeaab8314495ab71515cd29a0347",
            "513a4a45e8f940c9acdaa3bd30dd0c4e",
            "ecdfc241612f41528f7a056642c0d74d",
            "1e43a0a3d8334097a777f84ffd1a6d71",
            "0d2c5b55fd1f471f876f939f28205f13",
            "8f314ff35bca4f6f8bb18a0aa302110f",
            "3347c9d0ec724ce3bcef495b8a17e621",
            "5021ee5fa3fa429ebe2d85410f51b7b6",
            "699499f9801e4fb7967f524e9f8be9a7",
            "af3da674edd747c1b2effa7e026b9890",
            "6aadc754589c4dc08846b2ecf6eec005",
            "1872b65d1e024352baec24185aafd6fd",
            "3add776221b6476ea5200a079532a8f5",
            "4b8c44c65f5a472d9c56cc38cf5f86e0",
            "bb6f1d6f55644628803d02f431d79623"
          ]
        },
        "outputId": "688c0244-718f-42bb-966d-0187d118f166"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0b21a80ae0e444ca31ad76cb1052477",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f0c6edbb64743808f15db19448291a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2104.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acd3de89dfd0467b84f425b6d241f931",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2104.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5021ee5fa3fa429ebe2d85410f51b7b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2104.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6312, training_loss=0.19000222933737157)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-3V-0yv_r_L",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75MYAZtG1K-N",
        "colab_type": "text"
      },
      "source": [
        "The metric used for evaluation of the Stanford Sentiment Treebank (SST) data is Accuracy. The result is returned by the Trainer class object used for fine-tuning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGz07rX7_lsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "c8f6bf79b9a84c3c98a2675756c7c11c",
            "5a4a19eecb73432d8b933792b070dd89",
            "3817dbd4d0eb46499ce3cdf1560e7cab",
            "8563c739a3ee4f0995e9507422852533",
            "a8ef8833f8db4ba088190e1e86babab9",
            "a1e25aa6612d4d29b027479df04a2d84",
            "1f45bef924c64a5eb0ed4e0b6e45ee29",
            "3f7ce8a37be8401099e6ecf4bbfb86e5"
          ]
        },
        "outputId": "9e24482f-dd4f-4c36-b69e-4676ed46c5f6"
      },
      "source": [
        "model_result = trainer.evaluate()\n",
        "print(\"Accuracy: {}\".format(model_result[\"eval_acc\"]))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8f6bf79b9a84c3c98a2675756c7c11c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=109.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.9071100917431193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-V2TAFppOuz",
        "colab_type": "text"
      },
      "source": [
        "# Interpretability with Captum\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwaRQy2LrnQd",
        "colab_type": "text"
      },
      "source": [
        "The examples below use two attribution methods from the Captum library:\n",
        "- **Integrated Gradients** - the method requires configuring interpretation hooks to perform attribution for all three embedding layers in one step, and\n",
        "- **Layer Integrated Gradients**, computed separately with respect to each of the three layers:\n",
        "    - `model.electra.embeddings.word_embeddings`\n",
        "    - `model.electra.embeddings.token_type_embeddings`\n",
        "    - `model.electra.embeddings.position_embeddings`\n",
        "\n",
        "We will try to find out to what extent, according to these methods, each token has contributed to the model's prediction, or, more precisely, to its shift from the baseline output. \n",
        "Each method requires setting a target class index: 0 for negative or 1 for a positive sentiment. Attribution is performed for each target class separately. Scores will be assigned with regard to the model's output for the selected class.\n",
        "\n",
        "The shape of attributions is the same as the shape of the *inputs* parameter of the `attribute` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly7k0ryjp1C-",
        "colab_type": "text"
      },
      "source": [
        "Let's pick an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0uMvVUnzR4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "1c52480d-8a93-4333-c918-6d72bfbe2f1d"
      },
      "source": [
        "text = \"visually imaginative , thematically instructive and thoroughly \\\n",
        "delightful , it takes us on a roller-coaster ride from innocence to experience \\\n",
        "without even a hint of that typical kiddie-flick sentimentality . \"\n",
        "true_label = 1\n",
        "\n",
        "[x for x in dataset[\"validation\"] if x[\"sentence\"] == text]"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'idx': 857,\n",
              "  'label': 1,\n",
              "  'sentence': 'visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . '}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOQOBd8Hitie",
        "colab_type": "text"
      },
      "source": [
        "## Prepare input "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHJo7nNBiPjV",
        "colab_type": "text"
      },
      "source": [
        "Set a cpu/gpu device according to availability. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw0e2qtajCrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rlkMmJmiQg8",
        "colab_type": "text"
      },
      "source": [
        "Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxZg4TvKqPAH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The functions below **construct input tensors** for our sample and for a sequence of [PAD] tokens serving as baseline. We also need to define a **forward function** running inference on the model. The function will be passed on to objects handling attribution. \n",
        "\n",
        "Computation with **IntegratedGradients** requires altering the model by **configuring additional layers**. For this purpose, the Captum library provides the `configure_interpretable_embedding_layer` and `remove_interpretable_embedding_layer` functions. Configuring an interpretable embedding layer modifies the model. A model with interpretable layers requires input of a different shape. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J89L8HhDB1JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_forward_func(input_ids, token_type_ids=None, \n",
        "                         position_ids=None, attention_mask=None):\n",
        "    \"\"\"Function passed to ig constructors\"\"\"\n",
        "    return model(input_ids=input_ids, \n",
        "                 token_type_ids=token_type_ids, \n",
        "                 position_ids=position_ids, \n",
        "                 attention_mask=attention_mask)[0]  \n",
        "\n",
        "\n",
        "def prepare_input(text):\n",
        "    \"\"\"Prepare input ig attribution: tokenize sample and baseline text. \"\"\"\n",
        "    tokenized_text = tokenizer(text, return_tensors=\"pt\", \n",
        "                               return_attention_mask=True)\n",
        "    seq_len = tokenized_text[\"input_ids\"].shape[1]\n",
        "    position_ids = torch.arange(seq_len, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    # Construct the baseline (a reference sample).\n",
        "    # Sequence of [PAD] tokens of length equal to that of the processed samples\n",
        "    ref_text = tokenizer.pad_token * (seq_len - 2) # special tokens\n",
        "    tokenized_ref_text = tokenizer(ref_text, return_tensors=\"pt\") \n",
        "    ref_position_ids = torch.arange(seq_len, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    return (tokenized_text[\"input_ids\"],\n",
        "            tokenized_text[\"token_type_ids\"], \n",
        "            position_ids,\n",
        "            tokenized_ref_text[\"input_ids\"],\n",
        "            tokenized_ref_text[\"token_type_ids\"], \n",
        "            ref_position_ids,\n",
        "            tokenized_text[\"attention_mask\"])   \n",
        "\n",
        "\n",
        "def configure_interpretable_embeddings():\n",
        "    \"\"\"Configure interpretable embedding layer\"\"\"\n",
        "    interpretable_embedding1 = \\\n",
        "    configure_interpretable_embedding_layer(\n",
        "        model,\n",
        "        'electra.embeddings.word_embeddings')\n",
        "    interpretable_embedding2 = \\\n",
        "    configure_interpretable_embedding_layer(\n",
        "        model,\n",
        "        'electra.embeddings.token_type_embeddings')\n",
        "    interpretable_embedding3 = \\\n",
        "    configure_interpretable_embedding_layer(\n",
        "        model,\n",
        "        'electra.embeddings.position_embeddings')\n",
        "    return (interpretable_embedding1,\\\n",
        "            interpretable_embedding2,\\\n",
        "            interpretable_embedding3)\n",
        "\n",
        "\n",
        "def remove_interpretable_embeddings(interpretable_embedding1, \n",
        "                                    interpretable_embedding2, \n",
        "                                    interpretable_embedding3):\n",
        "    '''Remove interpretable layer to restore oryginal model structure'''\n",
        "    if not type(model.get_input_embeddings()).__name__ == \"InterpretableEmbeddingBase\":\n",
        "        return\n",
        "    remove_interpretable_embedding_layer(model, interpretable_embedding1)\n",
        "    remove_interpretable_embedding_layer(model, interpretable_embedding2)\n",
        "    remove_interpretable_embedding_layer(model, interpretable_embedding3)    \n",
        "\n",
        "\n",
        "def prepare_input_embed(input_ids, token_type_ids, position_ids,\n",
        "                        ref_input_ids, ref_token_type_ids, ref_position_ids,\n",
        "                        attention_mask):\n",
        "    \"\"\"Construct input for the modified model\"\"\"\n",
        "    input_ids_embed = interpretable_embedding1.indices_to_embeddings(input_ids)\n",
        "    ref_input_ids_embed = interpretable_embedding1.indices_to_embeddings(\n",
        "        ref_input_ids)\n",
        "    token_type_ids_embed = interpretable_embedding2.indices_to_embeddings(\n",
        "        token_type_ids)\n",
        "    ref_token_type_ids_embed = interpretable_embedding2.indices_to_embeddings(\n",
        "        ref_token_type_ids)\n",
        "    position_ids_embed = interpretable_embedding3.indices_to_embeddings(\n",
        "        position_ids)\n",
        "    ref_position_ids_embed = interpretable_embedding3.indices_to_embeddings(\n",
        "        ref_position_ids)\n",
        "    \n",
        "    return (input_ids_embed, token_type_ids_embed, position_ids_embed,\\\n",
        "    ref_input_ids_embed, ref_token_type_ids_embed, ref_position_ids_embed, \\\n",
        "    attention_mask)\n",
        "\n",
        "\n",
        "def place_on_device(*tensors):\n",
        "    tensors_device = []\n",
        "    for t in tensors:\n",
        "        tensors_device.append(t.to(device))\n",
        "    return tuple(tensors_device)  "
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BN3x0ISIazV",
        "colab_type": "text"
      },
      "source": [
        "## Integrated Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asVO1IpJyt8r",
        "colab_type": "text"
      },
      "source": [
        "To compute attributions with Integrated Gradients we will:\n",
        "- instantiate the IntegratedGradients class passing the *predict_forward_func* function as parameter,\n",
        "- configure interpretable embeddings layer,\n",
        "- prepare input tensors,\n",
        "- compute attributions,\n",
        "- remove interpratable embeddings layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMQKjnurz9qz",
        "colab_type": "text"
      },
      "source": [
        "### Compute attributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ZNDXGZIhW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the IntegratedGradients class\n",
        "ig = IntegratedGradients(predict_forward_func)"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0ifAYT8Ij_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "37c45fab-e6e4-4acb-f63f-6f5edaa159f4"
      },
      "source": [
        "# Configure interpretable embeddings layer if not \n",
        "print(\"Oryginal model input embeddings:\\n {}\\n\".\n",
        "      format(model.get_input_embeddings()))\n",
        "if not type(model.get_input_embeddings()).__name__ == \"InterpretableEmbeddingBase\":\n",
        "    interpretable_embedding1, interpretable_embedding2, interpretable_embedding3 =\\\n",
        "    configure_interpretable_embeddings()\n",
        "print(\"Input embeddings with interpretable layer:\\n {}\\n\".\n",
        "      format(model.get_input_embeddings()))\n",
        "\n",
        "# Prepare input \n",
        "input_data = prepare_input(text)\n",
        "input_data = place_on_device(*input_data) \n",
        "input_data_embed = prepare_input_embed(*input_data) \n",
        "input_ids_embed, token_type_ids_embed, position_ids_embed = input_data_embed[0:3]\n",
        "ref_input_ids_embed, ref_token_type_ids_embed, \\\n",
        "ref_position_ids_embed = input_data_embed[3:6]\n",
        "attention_mask = input_data_embed[-1]\n",
        "\n",
        "# Compute attributions for both target classes\n",
        "# class 0 (negative)\n",
        "attributions_0, approximation_error_0 = ig.attribute(\n",
        "    inputs=(input_ids_embed, token_type_ids_embed, position_ids_embed),\n",
        "    baselines=(ref_input_ids_embed, \n",
        "               ref_token_type_ids_embed, \n",
        "               ref_position_ids_embed),\n",
        "               additional_forward_args=(attention_mask),\n",
        "               target = 0, # Set target class here\n",
        "               return_convergence_delta=True, \n",
        "               n_steps=200)\n",
        "# class 1 (positive)\n",
        "attributions_1, approximation_error_1 = ig.attribute(\n",
        "    inputs=(input_ids_embed, token_type_ids_embed, position_ids_embed),\n",
        "    baselines=(ref_input_ids_embed, \n",
        "               ref_token_type_ids_embed, \n",
        "               ref_position_ids_embed),\n",
        "               additional_forward_args=(attention_mask),\n",
        "               target = 1, # Set target class here\n",
        "               return_convergence_delta=True, \n",
        "               n_steps=200)\n",
        "\n",
        "# Remove interpratable embeddings layer used by ig attribution\n",
        "remove_interpretable_embeddings(interpretable_embedding1, \n",
        "                                interpretable_embedding2, \n",
        "                                interpretable_embedding3)\n",
        "print(\"\\nInput embeddings with interpretable layer removed:\\n {}\\n\"\n",
        ".format(model.get_input_embeddings()))"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oryginal model input embeddings:\n",
            " Embedding(30522, 128, padding_idx=0)\n",
            "\n",
            "Input embeddings with interpretable layer:\n",
            " InterpretableEmbeddingBase(\n",
            "  (embedding): Embedding(30522, 128, padding_idx=0)\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
            "  \"In order to make embedding layers more interpretable they will \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input embeddings with interpretable layer removed:\n",
            " Embedding(30522, 128, padding_idx=0)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "turkFMM8Ng6n",
        "colab_type": "text"
      },
      "source": [
        "### Completeness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpltx2dbvNfa",
        "colab_type": "text"
      },
      "source": [
        "The Integrated Gradients method satisfies the completeness property. The sum of attributions should be equal, with certain accuracy, to the difference between the model's output for the sample and its output for the selected baseline (in this case a sequence of [PAD] tokens). Increase the parameter *n_steps* of the ig.attribute method to obtain better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raXBOcBN2up6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "e78d84d3-0549-47df-d2ae-47166503d056"
      },
      "source": [
        "def check_completeness(attributions_0, attributions_1):\n",
        "    input_ids, token_type_ids, position_ids, \\\n",
        "    ref_input_ids, ref_token_type_ids, ref_position_ids, attention_mask = input_data\n",
        "\n",
        "    # Prediction for the sample\n",
        "    scores = predict_forward_func(input_ids, token_type_ids,\n",
        "                                position_ids, attention_mask) \n",
        "\n",
        "    # Prediction for the baseline\n",
        "    ref_scores = predict_forward_func(ref_input_ids, ref_token_type_ids,\n",
        "                                    ref_position_ids, attention_mask)\n",
        "\n",
        "    # How prediction for the sample differs from baseline prediction  \n",
        "    diff_from_baseline = scores - ref_scores\n",
        "    diff_from_baseline = diff_from_baseline.clone().detach().to('cpu').numpy()[0]\n",
        "\n",
        "    # Put on cpu\n",
        "    if torch.is_tensor(attributions_0[0]):\n",
        "        attributions_0 = [x.clone().detach().to('cpu').numpy() for x in attributions_0]\n",
        "    if torch.is_tensor(attributions_1[0]):\n",
        "        attributions_1 = [x.clone().detach().to('cpu').numpy() for x in attributions_1]\n",
        "\n",
        "    # Sum of attributions\n",
        "    attributions_sum0 = [x.sum() for x in attributions_0]\n",
        "    attributions_sum1 = [x.sum() for x in attributions_1]\n",
        "    attributions_sum = [sum(attributions_sum0), sum(attributions_sum1)]\n",
        "    diff = diff_from_baseline - attributions_sum\n",
        "\n",
        "    # Find out which layers contribute to the score (order: order of inputs)\n",
        "    print(\"Class 0: input_ids sum: {}\".format(attributions_sum0[0]))\n",
        "    print(\"Classs 0: token_type sum: {}\".format(attributions_0[1].sum()))\n",
        "    print(\"Class 0: position_ids sum: {}\".format(attributions_0[2].sum()))\n",
        "    print(\"Class 1: input_ids sum: {}\".format(attributions_1[0].sum()))\n",
        "    print(\"Classs 1: token_type sum: {}\".format(attributions_1[1].sum()))\n",
        "    print(\"Class 1: position_ids sum: {}\".format(attributions_1[2].sum()))\n",
        "\n",
        "    # Compare sum of attributions and baseline prediction - prediction\n",
        "    print(\"\\nPrediction for sample: {}\".format(scores))\n",
        "    print(\"Prediction for baseline: {}\".format(ref_scores))\n",
        "    print(\"Difference from baseline: {}\".format(diff_from_baseline))\n",
        "    print(\"Sum of attributions: {}\".format(attributions_sum))\n",
        "    print(\"\\nClass 0:\\n score: {}\\n reference score: {}\\\n",
        "    \\n difference from ref.:{}\\n attributions: {}\\\n",
        "    \\n difference from reference - attributions: {}\".\\\n",
        "    format(scores[0][0], ref_scores[0][0], diff_from_baseline[0], \n",
        "            attributions_sum[0], diff[0]))\n",
        "    print(\"\\nClass 1:\\n score: {}\\n reference score: {}\\\n",
        "    \\n difference from ref.:{}\\n attributions: {}\\\n",
        "    \\n difference from reference - attributions: {}\".\\\n",
        "    format(scores[0][1], ref_scores[0][1], diff_from_baseline[1], \n",
        "            attributions_sum[1], diff[1]))\n",
        "    \n",
        "    return attributions_0, attributions_1\n",
        "    \n",
        "    \n",
        "attributions_0, attributions_1 = check_completeness(attributions_0, \n",
        "                                                    attributions_1)    "
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class 0: input_ids sum: -3.3746180015782667\n",
            "Classs 0: token_type sum: 0.0\n",
            "Class 0: position_ids sum: 0.0\n",
            "Class 1: input_ids sum: 3.6883858744307663\n",
            "Classs 1: token_type sum: 0.0\n",
            "Class 1: position_ids sum: 0.0\n",
            "\n",
            "Prediction for sample: tensor([[-3.4289,  3.6504]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Prediction for baseline: tensor([[-0.0543, -0.0380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Difference from baseline: [-3.3746176  3.6883852]\n",
            "Sum of attributions: [-3.3746180015782667, 3.6883858744307663]\n",
            "\n",
            "Class 0:\n",
            " score: -3.4288768768310547\n",
            " reference score: -0.0542592890560627    \n",
            " difference from ref.:-3.374617576599121\n",
            " attributions: -3.3746180015782667    \n",
            " difference from reference - attributions: 4.2497914565231554e-07\n",
            "\n",
            "Class 1:\n",
            " score: 3.650350570678711\n",
            " reference score: -0.03803475573658943    \n",
            " difference from ref.:3.688385248184204\n",
            " attributions: 3.6883858744307663    \n",
            " difference from reference - attributions: -6.262465621631463e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGv8Z_rPWpxs",
        "colab_type": "text"
      },
      "source": [
        "## Layer Integrated Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g85-8mizbf4",
        "colab_type": "text"
      },
      "source": [
        "Attributions can be computed with respect to a certain layer. We'll run the algorithm for three [layers](https://github.com/huggingface/transformers/blob/d5b0a0e235cc6fccba4f9013cdb54cee01e90a91/src/transformers/modeling_electra.py#L131) separately: \n",
        "- `model.electra.embeddings.word_embeddings`\n",
        "- `model.electra.embeddings.token_type_embeddings`\n",
        "- `model.electra.embeddings.position_embeddings`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtkHVIz80pmG",
        "colab_type": "text"
      },
      "source": [
        "### Compute attributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48x070y7El1n",
        "colab_type": "text"
      },
      "source": [
        "Assigning attributions with Layer Integrated Gradients requires:\n",
        "- instantiating the IntegratedGradients class and passing the `predict_forward_func` function and selected layer as a parameters,\n",
        "- calling `lig.attribute` to assign values to each token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhxxF_rIXDqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. model.electra.embeddings.word_embeddings\n",
        "lig_word_we = LayerIntegratedGradients(\n",
        "    predict_forward_func, \n",
        "    model.electra.embeddings.word_embeddings)\n",
        "\n",
        "layer_attributions_we_0, _ = lig_word_we.attribute(\n",
        "    inputs=input_ids, baselines=ref_input_ids,\n",
        "    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n",
        "    return_convergence_delta=True, target=0, n_steps=200)\n",
        "\n",
        "layer_attributions_we_1, _ = lig_word_we.attribute(\n",
        "    inputs=input_ids, baselines=ref_input_ids,\n",
        "    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n",
        "    return_convergence_delta=True, target=1, n_steps=200)\n",
        "\n",
        "# 2. model.electra.embeddings.token_type_embeddings\n",
        "lig_word_tte = LayerIntegratedGradients(\n",
        "    predict_forward_func, \n",
        "    model.electra.embeddings.token_type_embeddings)\n",
        "\n",
        "layer_attributions_tte_0, _ = lig_word_tte.attribute(\n",
        "    inputs=input_ids, baselines=ref_input_ids,\n",
        "    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n",
        "    return_convergence_delta=True, target=0, n_steps=200)\n",
        "\n",
        "layer_attributions_tte_1, _ = lig_word_tte.attribute(\n",
        "    inputs=input_ids, baselines=ref_input_ids,\n",
        "    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n",
        "    return_convergence_delta=True, target=1, n_steps=200)\n",
        "\n",
        "# 3. model.electra.embeddings.position_embeddings\n",
        "lig_word_pe = LayerIntegratedGradients(\n",
        "    predict_forward_func, \n",
        "    model.electra.embeddings.position_embeddings)\n",
        "\n",
        "layer_attributions_pe_0, _ = lig_word_pe.attribute(\n",
        "    inputs=input_ids, baselines=ref_input_ids,\n",
        "    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n",
        "    return_convergence_delta=True, target=0, n_steps=200)\n",
        "\n",
        "layer_attributions_pe_1, _ = lig_word_pe.attribute(\n",
        "    inputs=input_ids, baselines=ref_input_ids,\n",
        "    additional_forward_args=(token_type_ids, position_ids, attention_mask),\n",
        "    return_convergence_delta=True, target=1, n_steps=200)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofIDYnUr994Y",
        "colab_type": "text"
      },
      "source": [
        "### Completeness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9uTWg6O-NuF",
        "colab_type": "text"
      },
      "source": [
        "Completeness for attributions found for each layer separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15G8-Qg69_0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "bfcf6e47-f204-4a43-b8f3-5057441c0c40"
      },
      "source": [
        "layer_attributions_0, layer_attributions_1 = check_completeness(\n",
        "    (layer_attributions_we_0, layer_attributions_tte_0, layer_attributions_pe_0),\n",
        "    (layer_attributions_we_1, layer_attributions_tte_1, layer_attributions_pe_1)\n",
        ")"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class 0: input_ids sum: -3.3746180015782667\n",
            "Classs 0: token_type sum: 0.0\n",
            "Class 0: position_ids sum: 0.0\n",
            "Class 1: input_ids sum: 3.6883858744307663\n",
            "Classs 1: token_type sum: 0.0\n",
            "Class 1: position_ids sum: 0.0\n",
            "\n",
            "Prediction for sample: tensor([[-3.4289,  3.6504]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Prediction for baseline: tensor([[-0.0543, -0.0380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Difference from baseline: [-3.3746176  3.6883852]\n",
            "Sum of attributions: [-3.3746180015782667, 3.6883858744307663]\n",
            "\n",
            "Class 0:\n",
            " score: -3.4288768768310547\n",
            " reference score: -0.0542592890560627    \n",
            " difference from ref.:-3.374617576599121\n",
            " attributions: -3.3746180015782667    \n",
            " difference from reference - attributions: 4.2497914565231554e-07\n",
            "\n",
            "Class 1:\n",
            " score: 3.650350570678711\n",
            " reference score: -0.03803475573658943    \n",
            " difference from ref.:3.688385248184204\n",
            " attributions: 3.6883858744307663    \n",
            " difference from reference - attributions: -6.262465621631463e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HnTBKcFAjy5",
        "colab_type": "text"
      },
      "source": [
        "### Compare with IG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5iurfLHIpJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "6264ab1c-b826-4acd-f246-b9959546962a"
      },
      "source": [
        "# Attributions for input_ids\n",
        "ig_1 = attributions_1[0].squeeze().sum(1)\n",
        "lig_1 = layer_attributions_1[0].squeeze().sum(1)\n",
        "\n",
        "range_ig = [x + 0.5 for x in np.arange(len(ig_1))]\n",
        "range_lig = [x + 0.5 for x in range_ig]\n",
        " \n",
        "plt.bar(range_ig, ig_1, width=0.5, label='ig')\n",
        "plt.bar(range_lig, lig_1, width=0.5, label='lig')\n",
        "plt.xlabel('Token', fontweight='bold')\n",
        "plt.xticks(list(range(len(lig_1))), tokens, rotation='vertical')\n",
        "plt.legend()\n",
        "plt.title(\"Attributions with IG and LIG for the positive target class.\")\n",
        "plt.show()"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAG1CAYAAAAPyLn3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdedgcVZmw8ftJWIKyyBJBDCGIKEZQxIgLbiiMog6IogIu4KiofIw6jqM4OIrLuK84LoMrogwCbqgoIgqKCxAU2URBDBIWDREQRPbn++NUJ52mq7t6ebfk/l3Xe73d1XXqnO6u7n7q1HNORWYiSZIk6Z5mTXUDJEmSpOnKYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1DJYlSZKkGgbL0jQQES+MiB+03c+IeOAYt39zRDxgXNsbl4j4dET8V4/Hj4iIL09mm8Zp3O/jAPVGRHwhIq6PiLMnqI6DIuLMidj2OETEEyLidz0en199LmZPZrums4h4ckQsnep2SNONwbI0hIg4vQpE1u1YviQidm+7v6AKmNbqtb3M/Epm/tMY2/byju2vn5mXj2P745SZr8rMd8J4fqg7g9OI2C4ijouIZRHxt4i4NCI+HhHzRm37qLq9T9Xye+wzEbEoIr5T7XM3RMTFEfHfEbFxzeYfD+wBzMvMXcbQ1kb78XSSmT/NzAe37nd+NjPzT9Xn4q5x1jvVBxFTXb+0OjJYlgYUEQuAJwAJ7DWG7c2YAGQmqYLms4CrgUdk5obArsAfKMHkjBARjwNOB34GbJ+Z9wGeDtwJPLym2NbAksz8+xD1uT9OIV9/aRrKTP/882+AP+CtlMDlw8B32pYfA9wN/AO4GXgj8CdKUH1z9fdY4KCq/EeA5cC7qmVntm0rgdcAlwPXAR8AZlWPHQF8uW3dBdX6awH/DdwF3FrV9z9t23tgdXsj4EvAMuAK4C1t2z4IOBP4IHA98Edgz7a6DqradFP12Au7vD5zqtdgs+r+4ZTAbsPq/juBj1a3v1g9/3tXZe5ue622rJ7r8VV7bwIuAhb1eG/an+eXgW8P+N5uC/yoel+uA74C3Kft8SXAG4DzgRuBrwJz2h7/D+AaSoD+L+3t6VLX6cDLuyxf8X5W988EPj7Ac3hZ9f7fVb2Ob6+WvwK4DPgrcBKwZcfr9v+AS4E/dtlm3X7ca1/ZCPhc9XpcVb3Ps2vafARwYvV63gT8Cnh42+MPqV6vG6p9YK+2x54BXFyVuwp4Q7X8ycDSHp/NFa8z8AJgcUeb/g04qbq9bvU8/wT8Gfg0sF6X5/GQjtf+hmr5M4FfA38DrgSO6PJ+v6za/k+A2cCHKPvgH4FDO/aJrq9tXf1d2rkJ8AXKfno98M3O16y6fxjl4PKm6jXep+2xBwJnUD4H1wFfrZYH5bvtL9XzvQDYYSK/k/3zb6L/prwB/vk30/4oAcchwCOBO4DN2x5bAuzedn/FD3LbsoMoweO/Vj/U69E9WP5x9aM2H/g9VWBFj2C5un86HUEYqwaRXwK+BWxQlf098LK2tt1BCaxmA6+uflCDEtD+DXhwte79gIfWvEY/AZ5b3f5B9YO7Z9tj+1S3vwi8q7q9yg9123O9lRIQzQbeA/yyx3vT/jyvBQ4a8L19ICV9YV1gbtXWj3a8v2dTAvlNgN8Cr6oeezolkNqheq2OZcRgudrOXcCTB3wenfvTUygBzc7Vc/s48JOO1+3U6jl1CwJX2cf67SvV498A/rd6DvetXrdX1rT3iGpb+wJrUw5I/ljdXpvymftPYJ3qudzUth9eAzyhur0xsHO3/Yken03gXtU2t2t7/Bxgv+r2RygHGJtQPjffBt7T5LVva8uOlLO5D6v2k2d3tONL1Wu1HvAqSnA6r3pOP2TVz3jta9ut/i5t/C7lwGTj6vV9Us1r9jzKvj6LckDxd+B+1WP/RzkQnkU5QH58tfxpwLnAfSjfGw9plfHPv5n6ZxqGNICIeDzlFPfxmXkuJQg8YIhNXZ2ZH8/MOzPzHzXrvC8z/5qZfwI+Cuw/XKtXqgYz7Qe8OTNvyswllB6sF7etdkVmfiZLLufRlKB48+qxu4EdImK9zLwmMy+qqeoM4EnVKeWHAUdW9+cAj6IEoU2dmZknV+05hvrUg06bUQJmACLi0Crf9+aI+Ey3Apl5WWaempm3ZeYyytmDJ3WsdmRmXp2Zf6UETTtVy58PfCEzL8yS/nBE42dYb2NKMNL+PN5fPY+/R8RbGm7nhcDnM/NXmXkb8GbgsVVKUct7qv2tbn/spuu+EhGbUw5wXpeZf8/Mv1ACzv16bOvczDwxM++gvO5zgMdUf+sD783M2zPzR8B3WPl5uANYGBEbZub1mfmrAdoPQGbeQjmA3B9KrjuwPXBSRARwMPBv1etzE/DuPs+lc/unZ+YFmXl3Zp5PCTQ796sjqtfqH5R96WOZuTQzrwfe21ppyNd2hYi4H7An5SDv+sy8IzPPqGn3CdW+fndmfpVy5qGVA38H5btwy8y8NTPPbFu+AeX1i8z8bWZe06Rt0nRlsCwN5kDgB5l5XXX/2GrZoK4ccJ0rKD08o9qM0pN0Rce27992f0VgVgURAOtXAeALKL1e10TEdyNi+5p6zqD0Uu1MOQ17KiU4eAxwWWYuH6DN17bdvgWY0zCvczkleGs9l//Jku/7UcprcA8RsXk1IPCqiPgbJZVjsz7tWb+6vSX3fM9GdT3lAKX9ebyxeh7foPSKNrFle3sy82bK69P+vjfZJzt13VcoQdTalP3khoi4gdITet8e21pRf2beDSyt2r0lcGW1rKV9n30uJXi8IiLOiIjHDvE8oHyWWwH4AZTUhFsoZxjuBZzb9ly+Xy1vJCIeHRE/rgaa3kj5DHXuV+2vf+e+1H57mNe23VbAX6sgvF+7XxIR57XVs0Nbu99I6Tk+OyIuioh/AagOZv4H+ATwl4g4KiI2bNg2aVoyWJYaioj1KD0+T4qIayPiWkpe48MjotXbmR3FOu/3W95uq7bb8ymnuKGcCr1X22NbDLDt61jZI9S+7asatIfMPCUz96AEb5cAXXtogZ8DDwb2Ac7IzIurep5BCaS7br5JGwZwGvCcAcu8u2rHjlkGBL6IEhA0cQ33fM9GUh2gnMXgz6PT1bS95xFxb2BTVn3fe73+g743VwK3UfLW71P9bZiZD+1RZsVrFxGzKCkIV1d/W1XLWlbss5l5TmbuTQkWv0nJcR/mOZwKzI2InShB87HV8usouc4PbXsuG2Xm+jXb6VbPsZQ0jq0ycyNKznPnftVe7hrK829p36/6vbb9nueVwCYRcZ9eK0XE1pTP96HAptUB2oWtdmfmtZn5iszcEngl8MnWTDSZeWRmPhJYCDyIkssvzVgGy1Jzz6bkjy6knHrfiZKP91PgJdU6fwba5zNeRukZHGaO4/+IiI0jYivgtZQcQ4DzgCdW88RuRDml3q6zDStUp8uPB/47IjaofhBfT+lB7anqdd27CrRuowwgurvbulWP3LmUQWOt4PjnlB61umD5z8Cm1XMahyOAJ0TEhyPi/tVz2IzyntXZgPK8bqzKDPIjfzxwUEQsjIh7AW9rUGatiJjT9tetx/uNwL9ExGERcd/qecwDthmgbf8HvDQidooy3eG7gbOqNJwmBtqPq9PuPwA+FBEbRsSsiNg2IjpTD9o9MiKeU501eB1lH/sl5WDhFuCNEbF2RDwZ+GfguIhYJ8oc5RtV6Rt/o2afpMfnomrzHcAJlMG0m1CC51Yv92eAj7S9/vePiKf1qGdeRKzTtmwDSm/urRGxC/1Tt44HXlvVcx/gTW3t7PfadqufjvLfowS3G1ev6RO7rHpvSuC9rHrOL6X0LFPdf16snILx+mrduyPiUVVP+tqUA/tbqX9PpBnBYFlq7kBKTuqfql6VazPzWsopxxdWP/LvAd5SnbZ8QxU0/jfws2rZYwao71uUgPM8yoCczwFk5qmUwPn86vHvdJT7GLBvlDl5j+yy3X+l/IhdTpnN4Fjg8w3aM4sSWF9NmVHhSZRBXXXOoJwuPrvt/gbU5Ctn5iWUoO7y6rUaKe0kM38PPJrSQ/ebiLiJMgvJ1UDdhVDeTkkduZHymn99gPq+R0nx+BFlQNqPGhT7FKXXsvX3hS7bPZMyqO2JwO/b0gBOpwzUa9K2H1Ke89covZbbMljO7TD78UsoA/IupgRTJ9KWTtLFtyhpPtdTcuifU+XT3k4Jjvek9PJ+EnhJtb9QrbukSpt5FSU/u5tVPps16xwL7A6ckJl3ti1/E+U9/WVVzw8pZ066+RFlxo5rI6KVrnUI8I5qH3wr9b3fLZ+hBMTnU2bROJkyKLg1J3Sv17Zb/Z1eTDnDdAll1orXda5QnQ36EPALSgC+I+Xz0/Io4KyIuJnSa/7aLHO5b1i1/3pKusxyygEIEfGfEfG9Ps9dmnZao5YlSZoSEXEEZdaQF011W6ajiNgT+HRmbt13ZUljZ8+yJEnTSESsFxHPiIi1qnSgt1EGdEqaAgbLkiRNL0FJCbqekobxW0r6hqQpYBqGJEmSVMOeZUmSJKmGwbIkSZJUo+nVnybdZpttlgsWLJjqZkiSJGk1d+65516XmV2vzDltg+UFCxawePHiqW6GJEmSVnMRcUXdY6ZhSJIkSTUMliVJkqQaBsuSJElSjWmbsyxJkqTp54477mDp0qXceuutU92Ugc2ZM4d58+ax9tprNy5jsCxJkqTGli5dygYbbMCCBQuIiKluTmOZyfLly1m6dCnbbLNN43KmYUiSJKmxW2+9lU033XRGBcoAEcGmm246cI+4wbIkSZIGMtMC5ZZh2m2wLEmSpBnlcY973KTVZc6yJEmShrbgsO+OdXtL3vvMvuv8/Oc/H2udvdizLEmSpBll/fXXB+Duu+/mkEMOYfvtt2ePPfbgGc94BieeeOJY6zJYliRJ0oz09a9/nSVLlnDxxRdzzDHH8Itf/GLsdRgsS5IkaUY688wzed7znsesWbPYYost2G233cZeh8GyJEmSVMMBftNIrwT5JXMOqC94xI0T0BpJkqTpbdddd+Xoo4/mwAMPZNmyZZx++ukccECPmGkIBsuSJEmakZ773Ody2mmnsXDhQrbaait23nlnNtpoo7HWYbAsSZKkoTWZ6m3cbr75ZgBmzZrFBz/4QdZff32WL1/OLrvswo477jjWusYSLEfE04GPAbOBz2bmezsePwj4AHBVteh/MvOz46hbkiRJa65nPetZ3HDDDdx+++3813/9F1tsscVYtz9ysBwRs4FPAHsAS4FzIuKkzLy4Y9WvZuaho9YnSZIktZx++ukTuv1xzIaxC3BZZl6embcDxwF7j2G7kiRJ0pQaR7B8f+DKtvtLq2WdnhsR50fEiRGx1RjqlSRJkibUZM2z/G1gQWY+DDgVOLrbShFxcEQsjojFy5Ytm6SmSZIkSd2NI1i+CmjvKZ7HyoF8AGTm8sy8rbr7WeCR3TaUmUdl5qLMXDR37twxNE2SJEka3jiC5XOA7SJim4hYB9gPOKl9hYi4X9vdvYDfjqFeSZIkrYHWX399AK6++mr23XffCa1r5NkwMvPOiDgUOIUyddznM/OiiHgHsDgzTwJeExF7AXcCfwUOGrVeSZIkTQNHjPciIINcmXjLLbfkxBNPHG/9HcaSs5yZJ2fmgzJz28z872rZW6tAmcx8c2Y+NDMfnpm7ZeYl46hXkiRJa64lS5awww47AHDLLbfw/Oc/n4ULF7LPPvvw6Ec/msWLF49ch1fwkyRJ0oz3yU9+ko033piLL76YCy+8kJ122mks252s2TAkSZKkCXPmmWey3377AbDDDjvwsIc9bCzbNViWJEmSahgsS5IkacbbddddOf744wG4+OKLueCCC8ayXXOWpWlswWHf7fn4kjkH1D84wGhiSZJmukMOOYQDDzyQhQsXsv322/PQhz6UjTYafaYOg2VJkiQNbwo6Z26++WYAFixYwIUXXgjAnDlz+PKXv8ycOXP4wx/+wO67787WW289cl0Gy5IkSZrxbrnlFnbbbTfuuOMOMpNPfvKTrLPOOiNv12BZkiRJM94GG2wwlnmVOznAT5IkSaphsCxJkqSBZOZUN2Eow7TbYFmSJEmNzZkzh+XLl8+4gDkzWb58OXPmzBmonDnLkiRJamzevHksXbqUZcuWTXVTBjZnzhzmzZs3UBmDZUmSJDW29tprs80220x1MyaNaRiSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1DJYlSZKkGgbLkiRJUg2DZUmSJKmGwbIkSZJUw2BZkiRJqmGwLEmSJNUwWJYkSZJqGCxLkiRJNQyWJUmSpBpjCZYj4ukR8buIuCwiDuux3nMjIiNi0TjqlSRJkibSyMFyRMwGPgHsCSwE9o+IhV3W2wB4LXDWqHVKkiRJk2EcPcu7AJdl5uWZeTtwHLB3l/XeCbwPuHUMdUqSJEkTbhzB8v2BK9vuL62WrRAROwNbZeZ3x1CfJEmSNCkmfIBfRMwCPgz8e4N1D46IxRGxeNmyZRPdNEmSJKmncQTLVwFbtd2fVy1r2QDYATg9IpYAjwFO6jbILzOPysxFmblo7ty5Y2iaJEmSNLxxBMvnANtFxDYRsQ6wH3BS68HMvDEzN8vMBZm5APglsFdmLh5D3ZIkSdKEGTlYzsw7gUOBU4DfAsdn5kUR8Y6I2GvU7UuSJElTZa1xbCQzTwZO7lj21pp1nzyOOiVJkqSJ5hX8JEmSpBoGy5IkSVINg2VJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVMFiWJEmSahgsS5IkSTUMliVJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1DJYlSZKkGgbLkiRJUg2DZUmSJKmGwbIkSZJUw2BZkiRJqmGwLEmSJNUwWJYkSZJqGCxLkiRJNQyWJUmSpBoGy5IkSVINg2VJkiSphsGyJEmSVMNgWZIkSaoxlmA5Ip4eEb+LiMsi4rAuj78qIi6IiPMi4syIWDiOeiVJkqSJNHKwHBGzgU8AewILgf27BMPHZuaOmbkT8H7gw6PWK0mSJE20cfQs7wJclpmXZ+btwHHA3u0rZObf2u7eG8gx1CtJkiRNqLXGsI37A1e23V8KPLpzpYj4f8DrgXWAp4yhXkmSJGlCTdoAv8z8RGZuC7wJeEu3dSLi4IhYHBGLly1bNllNkyRJkroaR7B8FbBV2/151bI6xwHP7vZAZh6VmYsyc9HcuXPH0DRJkiRpeOMIls8BtouIbSJiHWA/4KT2FSJiu7a7zwQuHUO9kiRJ0oQaOWc5M++MiEOBU4DZwOcz86KIeAewODNPAg6NiN2BO4DrgQNHrVeSJEmaaOMY4Edmngyc3LHsrW23XzuOeiRJkqTJ5BX8JEmSpBoGy5IkSVINg2VJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVMFiWJEmSaoxlnmVJ9RYc9t2ejy+Zc0CPR48db2MkSdJA7FmWJEmSahgsS5IkSTUMliVJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDqeNWAyNNTXbEjWNujSRJ0urDnmVJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVMFiWJEmSahgsS5IkSTWcOk7StNFrGkSnQJQkTQV7liVJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmq4WwYkrQGGXrGEXDWEUlrpLH0LEfE0yPidxFxWUQc1uXx10fExRFxfkScFhFbj6NeSZIkaSKNHCxHxGzgE8CewEJg/4hY2LHar4FFmfkw4ETg/aPWK0mSJE20cfQs7wJclpmXZ+btwHHA3u0rZOaPM/OW6u4vgXljqFeSJEmaUOMIlu8PXNl2f2m1rM7LgO+NoV5JkiRpQk3qAL+IeBGwCHhSzeMHAwcDzJ8/fxJbJkmSJN3TOHqWrwK2ars/r1q2iojYHTgc2Cszb+u2ocw8KjMXZeaiuXPnjqFpkiRJ0vDGESyfA2wXEdtExDrAfsBJ7StExCOA/6UEyn8ZQ52SJEnShBs5WM7MO4FDgVOA3wLHZ+ZFEfGOiNirWu0DwPrACRFxXkScVLM5SZIkadoYS85yZp4MnNyx7K1tt3cfRz0zwUgT/nPseBsjSZKkkXi5a0mSJKmGwbIkSZJUw2BZkiRJqmGwLEmSJNUwWJYkSZJqGCxLkiRJNQyWJUmSpBoGy5IkSVINg2VJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVWGuqGyBp9bLgsO/WPrZkzgF9Sh873sZIkjQie5YlSZKkGgbLkiRJUg2DZUmSJKmGOcuSNKRe+dnQJ0f7iBvH3BpJ0kSwZ1mSJEmqYbAsSZIk1TBYliRJkmqYsyxJM4xzWUvS5LFnWZIkSaphsCxJkiTVMFiWJEmSahgsS5IkSTUc4CdJamTogYVegEXSDGbPsiRJklTDnmVpNTXS9GL2BErSjOfvwHjYsyxJkiTVGEuwHBFPj4jfRcRlEXFYl8efGBG/iog7I2LfcdQpSZIkTbSRg+WImA18AtgTWAjsHxELO1b7E3AQXjpKkiRJM8g4cpZ3AS7LzMsBIuI4YG/g4tYKmbmkeuzuMdQnaYJ5OWVJkopxpGHcH7iy7f7SapkkSZI0o02rAX4RcXBELI6IxcuWLZvq5kiSJGkNN440jKuArdruz6uWDSwzjwKOAli0aFGO3jRpVU6jI0mSBjGOnuVzgO0iYpuIWAfYDzhpDNuVJEmSptTIPcuZeWdEHAqcAswGPp+ZF0XEO4DFmXlSRDwK+AawMfDPEfH2zHzoqHVrzeTgM0mSNFnGcgW/zDwZOLlj2Vvbbp9DSc+QJEmSZoxpNcBPkiRJmk7G0rMsSZI0EzjQW4MyWJYkTahewQn0CVAMTiRNMdMwJEmSpBoGy5IkSVINg2VJkiSphjnLkiRJ09RIOf9eW2As7FmWJEmSatizLDU0/HRDHtlL0upg6N8BZ3WZ0QyWJWkKeNl2SZoZTMOQJEmSahgsS5IkSTUMliVJkqQa5ixrSpivKUmSZgJ7liVJkqQa9ixLmvFGmrTfKZ0kST3YsyxJkiTVMFiWJEmSapiGsYbz9LUkSVI9e5YlSZKkGvYsS5I0TQw9reYadqbP6Uc1mQyWJa3RRkpF8kd3WhspoFrDgk9J9QyWJUnTlgczWh24H89sBsuSJElahWdmVnKAnyRJklTDnmVJktZgTiEq9WbPsiRJklTDYFmSJEmqYbAsSZIk1RhLznJEPB34GDAb+Gxmvrfj8XWBLwGPBJYDL8jMJeOoW5KkcXMmgInnhUU0U4zcsxwRs4FPAHsCC4H9I2Jhx2ovA67PzAcCHwHeN2q9kiRJ0kQbRxrGLsBlmXl5Zt4OHAfs3bHO3sDR1e0TgadGRIyhbkmSJGnCjCNYvj9wZdv9pdWyrutk5p3AjcCmY6hbkiRJmjCRmaNtIGJf4OmZ+fLq/ouBR2fmoW3rXFits7S6/4dqnes6tnUwcDDA/PnzH3nFFVeM1DZNLOfmlKR7mop856n6PvZ3QKuLiDg3Mxd1e2wcPctXAVu13Z9XLeu6TkSsBWxEGei3isw8KjMXZeaiuXPnjqFpkiRJ0vDGESyfA2wXEdtExDrAfsBJHeucBBxY3d4X+FGO2qUtSZIkTbCRp47LzDsj4lDgFMrUcZ/PzIsi4h3A4sw8CfgccExEXAb8lRJQS5IkSdPaWOZZzsyTgZM7lr217fatwPPGUZemjyXvfWafNcxHk6TVmb8DWhN4BT9JkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVMFiWJEmSahgsS5IkSTUMliVJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1DJYlSZKkGgbLkiRJUg2DZUmSJKmGwbIkSZJUw2BZkiRJqmGwLEmSJNUwWJYkSZJqGCxLkiRJNQyWJUmSpBoGy5IkSVINg2VJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVMFiWJEmSaowULEfEJhFxakRcWv3fuGa970fEDRHxnVHqkyRJkibTqD3LhwGnZeZ2wGnV/W4+ALx4xLokSZKkSTVqsLw3cHR1+2jg2d1WyszTgJtGrEuSJEmaVKMGy5tn5jXV7WuBzUfcniRJkjRtrNVvhYj4IbBFl4cOb7+TmRkROUpjIuJg4GCA+fPnj7IpSZIkaWR9g+XM3L3usYj4c0TcLzOviYj7AX8ZpTGZeRRwFMCiRYtGCrwlSVpTLHnvM/usceOktENaHY2ahnEScGB1+0DgWyNuT5IkSZo2Rg2W3wvsERGXArtX94mIRRHx2dZKEfFT4ATgqRGxNCKeNmK9kiRJ0oTrm4bRS2YuB57aZfli4OVt958wSj2SJEnSVPAKfpIkSVINg2VJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVMFiWJEmSahgsS5IkSTUMliVJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1DJYlSZKkGgbLkiRJUg2DZUmSJKmGwbIkSZJUw2BZkiRJqmGwLEmSJNUwWJYkSZJqGCxLkiRJNQyWJUmSpBoGy5IkSVINg2VJkiSphsGyJEmSVMNgWZIkSaphsCxJkiTVGClYjohNIuLUiLi0+r9xl3V2iohfRMRFEXF+RLxglDolSZKkyTJqz/JhwGmZuR1wWnW/0y3ASzLzocDTgY9GxH1GrFeSJEmacKMGy3sDR1e3jwae3blCZv4+My+tbl8N/AWYO2K9kiRJ0oQbNVjePDOvqW5fC2zea+WI2AVYB/jDiPVKkiRJE26tfitExA+BLbo8dHj7nczMiMge27kfcAxwYGbeXbPOwcDBAPPnz+/XNEmSJGlC9Q2WM3P3usci4s8Rcb/MvKYKhv9Ss96GwHeBwzPzlz3qOgo4CmDRokW1gbckSZI0GUZNwzgJOLC6fSDwrc4VImId4BvAlzLzxBHrkyRJkibNqMHye4E9IuJSYPfqPhGxKCI+W63zfBgaz5QAACAASURBVOCJwEERcV71t9OI9UqSJEkTrm8aRi+ZuRx4apfli4GXV7e/DHx5lHokSZKkqeAV/CRJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1DJYlSZKkGgbLkiRJUg2DZUmSJKmGwbIkSZJUw2BZkiRJqmGwLEmSJNUwWJYkSZJqGCxLkiRJNQyWJUmSpBoGy5IkSVINg2VJkiSpxlpT3QBJklYnS977zB6P3jhp7ZA0HvYsS5IkSTUMliVJkqQaBsuSJElSDYNlSZIkqYbBsiRJklTDYFmSJEmqYbAsSZIk1TBYliRJkmoYLEuSJEk1RgqWI2KTiDg1Ii6t/m/cZZ2tI+JXEXFeRFwUEa8apU5JkiRpsozas3wYcFpmbgecVt3vdA3w2MzcCXg0cFhEbDlivZIkSdKEGzVY3hs4urp9NPDszhUy8/bMvK26u+4Y6pQkSZImxaiB6+aZeU11+1pg824rRcRWEXE+cCXwvsy8esR6JUmSpAm3Vr8VIuKHwBZdHjq8/U5mZkRkt21k5pXAw6r0i29GxImZ+ecudR0MHAwwf/78Bs2XJEmSJk5kdo1vmxWO+B3w5My8JiLuB5yemQ/uU+bzwMmZeWKf9ZYBVwzduMFsBlxn2WlZ55pWdqa1d00rO9Pau6aVnWntnYllZ1p717SyM62908nWmTm36yOZOfQf8AHgsOr2YcD7u6wzD1ivur0x8Htgx1HqHfcfsNiy07PONa3sTGvvmlZ2prV3TSs709o7E8vOtPauaWVnWntnyt+oOcvvBfaIiEuB3av7RMSiiPhstc5DgLMi4jfAGcAHM/OCEeuVJEmSJlzfnOVeMnM58NQuyxcDL69unwo8bJR6JEmSpKngNG7FUZadtnWuaWVnWnvXtLIzrb1rWtmZ1t6ZWHamtXdNKzvT2jsjjDTAT5IkSVqd2bMsSZIk1TBYliRJkmqMNMBPU6ea1/qvufJS4pL7RQ8RsTGwHTCntSwzfzKJ9W+RmddOVn2a3qZ6f1R/fmbVYs/ygCLi6xHxzIgY6rWL4kUR8dbq/vyI2GWITR0DXBIRHxymHU1FxKYTuf0e9e7aZFmfbdxrfC3qW9eHIuKhk1VfD433i4h4bZNlfbaxcUQMPdtNRMyKiA2HLT9APS8HfgKcAry9+n9Eg3KzI+LHY2rGyU1XrOq9ZEz1DiQiHhYRe0XEc1p/k1Tv5hHxrOrvvpNU58jfM0PWO9T+WJUdqM0RcUz1f6DPdsc21m2ybLqJiPUioueF0vpo/Jmt6tumy7JHjVB/03pnT3Qda7o1coBfRJzUYLW/ZuZBXcruDrwUeAxwAvCFzPzdAHV/CrgbeEpmPqTqXfhBZg78gYqIABZm5kV91ns35YIxN1T3Nwb+PTPf0qCOS4HzgC8A38sBdpiIeD/wLuAfwPcpUwj+W2Z+uUHZX2Xmzv2W1ZR9HPBZYP3MnB8RDwdemZmH1Kx/E1D7vDKzbzBX/fi9lHK25gvA/2XmjX3KXFBTb5Rqc6ggdID9ottr/OvMfESfcqcDe1Ge67nAX4CfZebrG7bvWOBVwF3AOcCGwMcy8wN9yq0LPBdYQNtZscx8R4M6LwAeBfwyM3eKiO2Bd2dm30AwIk4DntPv/Wywnb6vbcf63wL+NTP/NERdDwI+BWyemTtUBzR7Zea7+pT7POVzehHlewrKvvgvDeu9F/DvwPzMfEVEbAc8ODO/06fc8ykXuTqdsv8/AfiP7HOl16rs5sC7gS0zc8+IWAg8NjM/16DsKN8zc4FXcM/9se9rNeL+OFCbI+JiynUQvgc8mfL6rpCZf52AOnt+F2Tmh/vUN1L5ahv/DHwQWCczt4mInYB3ZOZe/cq2bWPQz+yvgH/OzKuq+08C/iczd+xR5uP0/v15TYN6Lwe+RolHLm7a3h7b69ujHhFHNtjU35rEGTPBmpqG8RCqeaBrBPCJbg9k5g+BH0bERsD+1e0rgc8AX87MO/rU/ejM3Dkifl1t7/qIWGfgZ1DKJuVHrZ89M/M/28pdHxHPAJrsxA+ifNH+C3BkRBwPfDEzf9+g7D9l5hsjYh9gCfAcSm9KbbAcEY8FHgfM7fjC3BBoevT8EeBpwEkAmfmbiHhi3cqZuUFV9zuBayi9swG8ELhfkwoz87PAZ6tejJcC50fEz4DPZGZdz+Szmj2dwfTbLyJif+AAYJuOA8cNgL4/nMBGmfm36gDhS5n5tog4f4AmLqzKv5DyA34YJejuGSwD3wJurNYdNM3k1sy8NSKIiHUz85IBepxuBi6IiFOBv7cWNvkR6/CZAdffGLgoIs7uqLfJj/1ngP8A/rcqc351kNIzWAYek5kLB2xnuy9Q3p/HVvevonQq9AyWgcOBR2XmX2BFIPpDoG+wDHyxqvfw6v7vga8CtcHymL5nvgX8tGrnXQ3LtAy8P47Q5k8DpwEPoLw3KzZJCdIe0KPOLYD7A+tFxCNYGWhvCPQ6c7dBj8eaaJV/MOWgovU99c/A2Q23cQSwC+UAjMw8r1vPbx+DfmZfCXyzCtR3Bt4DPKNPmcUD1tHNw4H9KL9Bs4DPA8dl5t+G3N7ngGf2WWdv4K191jmMZnHGtLemBsuHZ+YZvVaIiLf3eGxT4EXAi4FfA18BHg8cSDly7+WO6pRJVtuay8oenIkyu/pCvq2qcz2g0Sm0KvA6FTg1InajBLqHRLki42GZ+YsexVv71zOBEzLzxtLp2dM6wPpV2fYv3L8B+zZpc9XuKzvqavJjtldmPrzt/qeq59nvCwFYcSps++rvOuA3wOsj4pWZuV+XNl7RZLsT4OeUg4LNgA+1Lb8JaBL0rhUlN/r5rAxQBrF2RKwNPJvS63JHg/0CYF5mPn2I+gCWRsR9gG9S9uXrgaav/9erv5Fk5icHLPJfI1R3r8w8u+N1vbNBuV9ExMIReqe2zcwXVAdkZOYt0ezNndUKlCvLaZ4muFlmHh8Rb67qvDMi+n3ex/E9c6/MfFPDdTsNsz8O1ebMPJLS0fEpSuDc6jj4SWb+pk+dTwMOAuYB7b25NwH/2a1AVWft72cTrfIR8RNg58y8qbp/BPDdhpu5o8tvzkCn0gf9zGbmORHxGuAHwK3A7pm5rE+Zowepo2YbN1EC+89UvdnHAh+JiBOBd2bmZQNur1+gDPCRfm2vzmKvFtbIYDkzj+9cVr2pN7TSDLqtU633DcrR7jGU0y3XVA99NSKaHCEeCXwDuG9E/DflS26ij7y+ApwWEV+o7r8UaPQB7Tgw+DPwr5Sj/J0oPUa9jtS/EyXv8h/Aq6sDg1t71VcdxJwREV8cIZi8MkoqRlZB2WuB3zYo9/eqt/M4ypfq/rT16PUSER+h9HqcRjmd2ur9eF9E9EzTiVXTQNYB1gb+3iT9YxjV63oFK3v/BvUOSo7lz6ofhwcAlw5Q/tPAHymB+U8iYmtKj3E/P4+IHTPzgkEbnJn7VDePiJKDvBElNahJ2aOrA8z5OUDK1agy84zqtdkuM39YpTg07fW8LiK2ZeVB+b6UA6R+vkQJmK+l9N4PmhJ0e/VaterdlmZnAb4XEacA/1fdfwHN80X/Xn1Ptep8DH32pzF9z3wnIp6RmQPltVb1D7w/jqHNl1A6O75OeV+PiYjPZObHe9R5NHB0RDw3M782aIURMQd4GfBQVh3I2CitB9gcuL3t/u3VsiYuiogDKJ1F2wGvoXQUjF1EfJtVA/F7UfbBz0VEo7NB1e/jm4CFrPpaPaVB2dmUTqmXUtKCPkT53X8C5XP0oKbPpanM/GhV92aZeV2vdVYHa2rO8luB46tTX+tSvqQeTul5OaBKtagru1uP0+pN69+ecpnwAE7LzCaB3EgiYk9WXpr81Mw8pWG531MODL6QmUs7HntTZr6vT/lNgBsz867qx37DfrlQVblTgeflqnnWx2Xm0xqU3Qz4GCV9JChH+a/Ncnn2XuUWVOV2pXzx/Qx4XWYuaVDnSyn71D2C64jYKBvmu1a9cHtTTocf1qTMoCLizMx8fNwzV7sVGE3ogLuIeFvb3aT0IM7OzJ49qVFyL7cDLme4QG4oMYbcxyHrfQVwMLBJZm5b/eB/OjOf2qco1QHMUZTT9tdTDk5e1G9fjojLgNcDF9B2xqtpcBYRe1AO/hdSPne7Agdl5ul9yr0POItyhg5KesNjmvTcRsTOwMeBHYALgbnAvpnZ9yxJFaje40ewYYByE3BvSgB3O5P3+XkQ8AbumSvds81RUqUe2/qOioh7A79o+vmJiGdyz6C353iBiDiBEqQfQDnIfiHw28xsNNgwIg6nnMH6RrXo2cBXM/M9Dcrei3Lm658o780plF7Wnh02w6h6c2v1O5NdbeMHlPShN1DGdBwILGv4Gbgc+DHwucz8ecdjRw6RMtZX9b34eUrcdBfw/M66VydrarB8EbBDZmZEHEzpQdydcvR1dGbeY3aK6DMiPDMbnaaNkhR/3EzZqSIicoSdpOrhXcCqX+pfalDuHgMrui2rKTu336mvcal+qGtl5q+G3O5AA0smUww5eKyt/L+33Z1Dyd3+bb/epqqXdWNKbwmU/PcbJjqdJSLOBZ4CnN56TyLiwszcYYLrPY+Sc3lWW70XZI/BQl22cW9KisNNDdf/RWYOe8ahtY1NKQOggzKArWuvU0eZbgPIzh8gkFuLcsYvgN9l/7EjrXKPbLs7hzKA9M7MfGOT8lMhSmrYpyn5xyvSTTLz3NpCrBxU2AoWq17fc5rsTxHxaUpv6W6UwdP7Amdn5sv6lPt1Zj6i9V5WZ/p+mpmP6Vdn2zZ2pu0zn5m/blp2skXJib6m7TVej/I9uaRB2XMz85Ht+31EnJMNBv9HxOMz88yOZbtm5s+GeiINVAdfz686HR9NmUSg50HDTLZGpmEAt7cFgE+jBK93Ab+tvnS7+ece20ua5zSeC7wlymCOb1R1jyPB/x5G6UFsP60UXVIOG55WOgbYljKbRutLPSmnevu5OyLmZzUTQBUoNQ3afxYRSyhH6V9r9U43aO8wo9s/1OOxpARZ/eptPxCbBSyiT7rKFBt28BjV+qu8ZlGmuWtypuPZlIG5K04jV22pPY08Jt1yHyd6nAHAbZl5e6ve6rup52cgamYRaG0j+88i8Ovqvfw2bekTA3QG7AP8KDO/W92/T0Q8OzO/WbP+q4FDgAfEqoNEN6Cc2WlS5/8DvpLV7C9RpjPcPxvkm3YJMH8WZUBlk3pbg4C3ycx3RsRWwP1yZQrWRLkzMz81RLkvAGdFSSWE8nnqO2NI5XFVsHt+Zr49Ij5EGZzbT+ug5YaI2AG4Fug7LWB1RrJlSfW34rHsMYNHRHw0M18X90yNABoPkB3WCZSzOS13VcuazHbVeq2uqXrxrwY26bF+uyMpAwrbfbzLsnG6MzMvAcjMsyJi1EGd09qaGizfVn1w/0w5Un5D22P37lYgM186jopzZQ7YJpRejPdVQeF249h+R12Pr/4PsxOPY/7mRZSZD4bpmT4cODMizoAVU0kd3KRgZj4oytzV+wGHV6fvj8v+U9YNPLo9M3drsl4f7Qdid1J+GPYew3YnyrCDx2q3RxlA1M/LKKfmW6eR3wf8gokPlict97HDGRHxn5SZCPagBJXf7lNm1FkE1qMEyf/UtmyQzoC3ZWYrGCMzb6jSbroGy5SBSN+jzBrQnnZ0U6+AqMMrMnPF7EVZZvt5BdA3WO4IymYBj6TkDzfxSappQIF3UmZN+QTNAqNRfDsiDqF0trQf0PR8vTLzw1GmfWylurx0gF7af1T/b4mILSkDMJvMFHRUlBS6t1D2xfVpNmD6XMp+F8B8SipRAPcB/kTvsTLHVP8n9BoENdbKzBU51tXBbtPZrt4VZZatf6d8p20IvK5XgRjPrC7Dum9Hnavcb3BgPqOsqcHyaylTEs2ljOj8I0CU6dS6njav67FpGWLHeCBl1oStaTb4bGgRcUxmvrjfsnZNcqwauBDYgmYDizrr/351+q11uu51TU7ntpU/Gzg7yhzTH6YMaOwXLI8yun3glJOIeF9V3/eyZkDpNDXs4DGq9dvnl55N+Rz2nSuZ8mPZfhBzV7Vsov0r5eDtNsoAtFMowdFEO4xygHABZUqqkzOz51RWOeIsAmPoFOg2g0Xt70yWXP4bKalww5rdni4WZbBT0wClPSi7k5Lb3TO1oM3YpgEd0IHV//9oW9ZzCrgVK5W0sGFSw74TZfaOD1Tlk5KO0a++1jo/adK+tnLbAETEZ4BvZDWIMsrYm2f3KXtu9X8cv2GDWhYRe2XmSQARsTdlZqQmrm/7POxWle93gZyxzB41pM901Nl5f7WyRuYs9xI1o35j1UFJ95ANp8qJcqGOfYA/UNIEvtE0TWBYnfmA1enc87PHfKpRf8EMAJrkEkYZPLMTpUervQekSQpH13mRs8HlYKNcEW4fSs/ytpQemOMb5PS9C/h5DjG6vS7lJHsMrKhe44cB53bma05n0X3w2Aub5g5XKTUtdwJ/zsy+PdPVAeuBrDrY54u5Go24bhcRr83Mj/VbVlP2d8DDcuV0ketSPvP95vKdR+nVav1I/5QyOHZpfalVyn8euIGV89T/P8oAxYOalB9GRHyA0unwv9WiVwJXZua/15caS71nUT4D51RB81zKBaam5ViDcan2pTnZYNByjHBBrGr9e+Tod1tWU/bsrMYfRcTzMvOEJnWOoupE+AqwJeUA7ErgJdlg6rbO3+m6ZTVlt276/avhGCx3iIg/Zeb8Cdz+Kyl5tI17SUeo682UuTDXA25pLaaM3D4qM9/co+zWdY9Bs9HxUTNCuMkRf5Vv1jKHMtDp3Gw2Sv2PlNO+x2fveaA7y7VGt99GyR9rPLo9In7LgCkn1Y/8Kyg9A7e0P9S03qkQEY/MzHOjbfBYRDwr+1ylbUx170zbjAkDnEYepq6uOY8tE5z7WPfj2XSQ61CzCESZheZYVp7KfhHlQGiPhm2+N2V+6N2rRacC78ous8SMS5SLMLySttl+gM9mGYfSr+zawKtZOffw6cD/ZoMBglGmmXwBJS/0aKppQCcqKIuIp2Tmj6JmsHk2zCsfof6BB2t321+bBoDVuqdQDthaZwVfCDwxe8yKFBE/p5yNeRrwdMq0ludMZodERKwPkJk3N1i3lUrxOsoFtVo2BPbJVef+7yw7ZfnZEXF8Zj6/ut06S9p67AeZ+U/1pWceg+UOEXFlZm7V4/Gh5o2MiO2zjBrt+oHNIWdNaCIi3tMrMJ4Jogye+WhmPrfBukPP4FHlMG7Hqu9tk+D+BOA1uXLe7UHq/FZmTucc5VVEuaTrSzLzwur+fpTLmD96als2XnUHey0TdZo3Vl5h8fGUQKFlQ+CubDB1XLWdgWcRiIjzMnOnfstWFxHxWcq85q15519MeY17XeG1vfykTQMaEW/PcrXM1nz5re+41sF107mLh6l74DNnVbnzKTNwtF8Qa3FmPrRhvZsAb6PtQirA27P3AL8AdqSkHZ1K+T7fkTKDyBmZ2WRg4kAi4kWZ+eW6dM3skaZZfc88mTJd3KfbHroJ+HZm1s5h39ZxMXTH1LDaD4S6nL2etrM5DWtNzVnupV+QdQxl3sin0TZvZIPtvp4yQK3b7AmNZk0YVma+uTr91RkENklpeAzltOxDKPlRs+lzwYyYmHl8l1Zt6NXWj2bm64CTImLgo+wol29+LWWw2XmUfOmfs7LHqluZ1hH9BsDFUUbSD5RyQtmfOre7ypH6NLMvcGKUQW9PAF7CqgPCVgsT+UPTx9BXWIyIDbNcSnwTBpxFoLI8Il7EyouD7E8ZzNVIDDkH8CiqvM4jKKkYa7Hye6ZJjuyjOnrufhRlarYm9bamAf1E35XHIDNbqYCvpgwOX8DK13iie72GHaw99AWxYMWgxUZzMrf5PCWo/lvrAKJ6T79H+b4ae7DMyokBBs7ZzREuNpNTm5/da19Y7Xph18ie5R75uAE8KDNrLwUdI84bGRFzsmNS9G7LxqkmCPxFw5SGxZTc3xMoX5gvobxGE9pTHREfZ+V7NIuS+7wkM1/Uo8xIR9nVfvEoytywO1W9Ru/OzNo5tsfR+1hzur3xHLNToQqKvkkZmb5PZv6jT5EZp8/3RE70+1OlNPwjM++uXu/tKYNBa1MEIuI7lJkv7qItUKZhAFmlX32ccnXHpATur8lqCscGbR5qDuBRRLlK6L91qbNvkF+dJXleZv6huv8A4MQmp+wj4kBKGsaETwPaUe/3KXnhv2LVXt4Jm31gxDNnA18Qa5T0guqz8gTg/ZSOiNsoF8l5NXBmTtIc/IMa5UAzpiY/+xLKwfQsSprMAZTvmQC+nJk9O7dmmjU1WB46H7e1U0YZbX4IZd7Isxv2YoyUxD+sYYLAtrKLM3NRrDpR+oSfYql+iFrupATKEzbBelXnOZn5qCgXg3h0Zt4WERc1PWU4RH2tOWa3BdoHgGxAuZR07YHBVOgSPN6XMnL7Nmg26HMmGeV7Ykz1n0v50d+YMufwOZQ54l/YoOzAF02JMovEl5psv8c2zs3MR/Zfc3wi4qxhU4Ai4qmU+Ycvp/zIb02ZUq3xVVpj5TSg+1EuiT72aUA76pvwC+K01dV+5myowdpD1tvq+HgDZb9vt0E2GB/R1rF1L+DXlNkanjARKW/VWYZa/dJVqm0MfKAZU5ifHWUawl5jOsYxreq0saamYaxNuarOKsFXdTqv36WYW/NG/hcDzBsZEVsA96fMmfoIWDHl1YaUeWYn0q2ZeWtEEBHrZsmd7jkqvs0tUaZDOi/KTB7X0H16qLGpfrT/adgf7RGOspdGmR7pm8CpEXE90HSGh86UEyiB5GLK6O/LuxQbxxyzk+lZU92AydQeDEfE5qycP/fszPzLJDQhMvOWiHgZ8MnMfH91INfEuRHxqMzsDDRqZbkk/dYRsU62zRU7oKHmAB7Rj6MMlv16R519x4Fk5mlR5s5ufR/+Lqv82gFM2jSglZ9HxI6ZecEk1PVBym/V+1h1yrbWsq5GTcVrCxAPAL6fK8dH7E8ZCNdkMPG/Vtu6JSIuycwPMnFzLz+HMr3kxpQZgoYxzMVmdqXkYz8DeCMl1fIBEfFeJig/uyUznzxR256O1tSe5e8Ab+78somIHSk9rr2u1jdsnQcCB1FSGdpP1d1Emf5qwkYyR7li00spXzJPoXyY187MZzQouzXl4i3rUE51bkT54e47Fc4oIuJM4CmD/GiP8yi7Sq/YiPJF3bcNEfFOSl71sZQfhNa0db8CXt3vi6U6QNicVU+/NTr1PVUi4r6smgM/rds7rIh4PmV+2dNhxQVy/iMzT5zgen9NOfPwEeBlmXlRNJ826xJKEHcF8Hcapo5ExJcoYwNOqsoBzeeRjzITTae+6R+jiDJFZbc6G+VJxxCzPFTl3k8JIC8HjgO+mRM4DWjbmZ21KEHR5ZSDgwlPC5qqVLFWWgwlaG6Nj3hWNpu27i2Z+a7q9rpDHAQN0s6LKTPAfI8yWG+V+d+bHCxGmQv9LwxwoBklF/wnwBtaZ0CrHurXUHrRG11VdRgR8SjKFI3XVvdfQjnDcgVwxDTt8Bnamhos115vvd+PUUR07UXOzCYXVSBq5nGeLIMGgVNlmB/tiMkfBd1W92+yY4qfqGYR6PZYx3qHUgYo/ZmVl1Ge0B+/UUTEXpSBZ1tSvty3Bn47UekqU6368dmj1ZscZT7dH/Z6T8dU7xMpOYw/y8z3VYHD6xqe0u2aQlKXOhLVRYoi4gZWnb6qVa7RPPIzTQw5y0NV9hDKVfsWZOY7ImI+sEVO0OWupyItqC1V7AGUawO0NE4Vi5XTPSYlZ3ig6R5jwPEREfEmSgD5qaxmcZmEVMfXUHKiHwBc1f4QDQ8WhznQjCnMz46S7797Zv61+q46jtKbvxPwkMyc6IuiTKo1NQ3jPj0eW69P2fb5QudQTk03PvWWmV+Lct33zqnnGgXbw6pSR7ai9GTfBOxAgys5jZDSMKo/VH+zWDnCuN+R3VSMgm65peqBbPU27gu0Bm32a/frgAdngwFJ08Q7KYNEf1jlBO5GmY93dTWrI+1iOROcigQrZqv5Sdv9yyk9Rk3KDho4PTLKZYz/xAiXD6/yQ19Pyd09uJXi0CTHdIQ6NwfeDWyZmXtGxELgsZn5uQbFh53lAcqBeOty1++gfK9+jQm63PVEBMMNjJQqVnUuPY+Vl0v/YkSc0K/HM+45PmITykxMZ0VEv/ERl1R1PiAiflrd3zQiHpyZv+vX5mFk5pHAkRHxqcx89ZDb6HUJ77oyvwd+HxGHZuaubfnZ21LOZE/klKSz2/aBF1Cu3fA14GsDpIvNGGtqsLw4Il6RHZeOjTJrRM9R25m5ytRvEfFByuVvG4mIT1NylHejXC50X8qgiQlTpQgcRDltt6Lnkh7T1bWlNNw3yoDAS4E3U2bFmAwXdwbmEfG8PmXeQwmKt4iIn1GOsjenfNH+b6+CY/BC4GPAJymv7S+BF0WZV/TQPmWvpOQ3zxR3ZObyiJgVEbMy88cRsbpeRS+Ac6JcHKE1ndoLgIGv8jhE3XMpeYidB9YTMQ3bp4HTgG1YNU0saHgp5coXKN+hj6vuX0X5zpjIC9Z8sar38Or+7ylXR20SLF8IbMEAl2tvM1WXu540OfrlyF8IPDyr2Z6qXNrzgH7pAaOMj7iBcjGuJ1d/D6FMbXlYFTA/rr7oaIYNlGHkA83JzM9umR0Ra2W5+upTKVPjtqx2seVq94Qaeh3wjShXYGoFx4soebn7DLite1GmZGvqcVmmnDs/M98eER9iYns8oVzJa9sB0y6mbOBApVtg3jNYn8qj7KrXry7X/cxuC2PlBPaXA6dHxHdZNVdtwqaCGtENUa5Q9RPgKxHxF8rp6NVOZmZE7EIZxNu6cuBRmfmNHsXG5SuUoO9ZlAsWHAhMyGnVcfSMVbbNzBdEGYjV+vGObbiLbgAAEhhJREFUfoVGtFlmHh/liqVk5p0R0fPqfTGe+dHvqMYaZLXNuazsjFBxNeVAr3WWbV1WTVPoasRe9KdRPq/bAh+mzE3+98x86QjbnAyjHGg+mZW/M88fe8u6+z/K/NDXAf+guoBSRDyQmdX508gaGSxn5p+Bx1Wnj1tT8Hw3M3/Ur2zH6aHZwFzKKbimWvlWt1SnPZcD9xug/DAupKSeDDKCf0pSGqLMyfkM4P6x6nQ8G1KmkGti0o+yq4EW3eYD7XVVrVZ6yZ+qv3Wqv+nuN5TLc/8bpedoI8qsMKurcykDWbpenWsCbZqZn4uI1+bKCxc0nt1iGCMGygC3V2dTWgHktrQFoRPk7xGxaVudj6H/j/U4vg+OpAzGuu//b+/OgyUr6zOOfx9kChBnWGREo0MyTIiALBa7FZYBhMoIEhKGTCmyFSQpRRIEMTGRAAaQQSWFRBEQRlFQGBMCCBMmJYtssjkYVou1KgiyRAqmYCLbL3+875nbc6e7b2/nnO57n0/VrTt9uk+fd4qh+z3v+1sknU5udz2A951MXgYeVGqjHsA+wF3FZ3snseHdioh/gJXfV98ntSOfqZQ0/lKUkMA/IF3faDbEZ89nbLX+DtLfuVQRcbqkn5LmL0sbQpnWIH8HTyZTcrJcBPtHqqXZtJ5mm4SAxu2hN4Hn8jZEp36iVJ7sq6SY4SCFY5TpK8AySQ/Q+epJXSENz5C2gQ9g1ZCY5aTJWSfmUv1dduPd/9qkHYpn2p0wwklTe0bE26RVtO9Byoyvd0il2hk4RFJRWQKopK500Xzk2Zzn8Azp/79hdjLwn8AsSZeSdqiOKPmax5MSgefkz6qZpMlDS/nmAzXplClpITBhM6GIuFSpFnbR7vrAKLHd9Yi6Mv8Ubqrw2tdHahJzj6RPRyplt1GF1+9WLzealcdnF1rNkfIOb9vXjKKpWg1jBSkGt+VLgPUiYpMm584Bno7UsGIusA2pkH/XJYMkrQWsHR2UwemHpAdJE9z7adgmjM66y1VW2H3cdadFm05lLc6pPAu6zVjWIGUjTxgfp+ZdqooazedHid0du6ERa6IyKOqyssQAr7s/aWtzFinpbgZwakRcXeZ1+5VXeXchfY7+PCJerOCaa5JqJYtUK7mjz45mnw8a8u6Zo0TSx0m7trWGp0jaNiI6amNeF0n7kHYmtgSWkm80I+KmNufsAdxJ6rS5Iyk++1rgBlK8c2nx2f3Mo0bRVJ0sty3Bk70VEU83Ofc+UnzzH5CSfK4CPhQd1CxueI+e6nr2Sm1K5XVw7q4RcWv+81VlT5Ibrtt1FQ5JfwrsARxNChV4hJTYsW/Zd9lNxvJB0pfEH3bw2nNIq2GNCWSvkCbQMyLi0NIG2gVJ65GK7o9KExWrmKQ/A24oFgDyLtrciPiPEq61V0TcIKlpJ9JoU7teAyiJZhOT9ANS6/R/Ay6OiEdqHtJQ6/ZGU9IZpJ2vHUiJrv9NaoK1ZclD7WseNYqm5GS5H8VKhKQvACsi4lx10f5ZfdT17JWks0nbOVfTZYcrVVjYPV/jdlKM9b502Vik5rvsolNVUT3gN6TGNxPW1G52M6Ox1tultdu24SbpA6QV5aJG7S3A3w7zl49ybfFxxzr+fOzyWqdGxMk5X2C8aJcv4Bu/6kiaQaqmcSTp3/Ei4IcRsbzWgQ0hSduw+kLahA3Lcnz2UaRY5dOBXzHc8dkjZ0rGLPfpjRyAfxhj1Q+mdXF+P3U9e1V8Ue3ScGyi0nF1JQ4UVTjm0X0VjtqyoCNi+sSvauldkjaJ3AFPqblBkTA3tI1jrHSLSHVui5KJn8rH9qltRBNrVn+6lO+ZPFFeA1gSEVd0f3o8JemY8U9I2tAT5sGJiFck/ZjUw+A4Uj7HiZK+ERE91/SebCRdTArrfJBVS7x20t131OKzR44ny907klTG6fSIeFLSbFLGbaf6qevZk4jYs4fT6koc6LkKR91Z0Eqd7XbPD2+KzhsxnADcKulx0sr0bOAzktYlJ9DZlDQzIhpXTb8r6bjaRtOZe/JO1jfz42OYoHZ9PyLi7bzL1+1k+TJSsva9jO0IrXxbOq8rbW3k0LgjSK3XLwF2iojncw7MQ/TRAGcS2qXX8ImI+ELDwyPysdJzBaYSh2FUTNKNpHaQvdT17PWaXXe4qiukQQNo3ynprOLDoyFBcaMyPzzyyveOpNq4kLYd7y4m8B2cvxaweX74q2FJ6rP65LJMixiLZf8EcGRE7F3fqNrLN3gnAR/Nh/4LOC0iXm19Vt/XPBN4kVSTurFaSScd5n5Aqnxxi+NpB0/S5cA3I3WjLI4tjIi/k7R3RPy0xuENFUkXAV+PiIfqHoutzpPlDkm6IiL+Qqu34Sx6v3eUPZ0noavppDJFryQtIXe4iohtc+b4sojYus05tSUO5OsPpApHVVnQSqXTPlxkfSs1K1jW7t9FPwlKNvnlBJpzSQlSQbpxPTYi/qfWgXVA0nTS52LpzWokPdnkcETEhKvDSrX2d8s/c0jlPG+JiHMGO8qpydVGOpfnBleT8l1+R5dzCyuXJ8sdkvS+iHhW0gmkVsarJNlEyWWk+tGQLLYy0aZZIk6Lc2tJHKirCkev8mR5brGaJWlDUihGu8lyzwlKNvlJ+h5wXES8lB9vCHxtmP9dSNqatN1e1IN+ETg8Ih6ob1Tt5RvbHYE9SSF2KyJi8/ZnWTuuNtI9SY+RaoaPL/E6tHOLqcQxyx2KiCLG+F3ABcBvSdt+iyN1BGxL0q056L6omrDyqfT2MWPQY27QS4erQl2JA3OpvrFIP84gNX65kfTfdHdWzbJfTUScnH8PextWq8c2xUQZUliBpIFXlRiw84HjIzV8QqkW/QWMtfAduLz7dDywSUT8laTNSKFiE+YM5FCXdUnJy7cAO0ZEN51OrbnLSPklrjbSuRdiyGuoT2VeWe5RLvGyADiI1KTkoxOcUhtJ25G2c7ciJRjOBOZHRFdd16oIadAQNRbpVM7In0/+ss2H74qI30xwXtv2yRFx9mBGaKMo7+rMHbeyfHO78Km6SfplRGw70bEBX/NyUqLeYRGxVZ48397hztm/ANuTtr1vI3323BERK8oar1kzkr4FrA9cw6r5TA7HGwJeWe7d86TYov8F3tPpSfkLb7zl0WW3um5ExC9yPFTXHa7GvU8VHZBqa9/ZqyIjP5ev6mZloJ9yczb5fR24Q1LRkOdgUijUMHtC0kmMVQj6FPBEydecExELcklPIuI1SZropPzaz8HKGOsjSLkd7wXWKmmsZq2sQ5ok79twrNPScVYyryx3SdJnSGEBM4HFwBXdZK9KeorUvvYl0sR1fdKk+zngLyOilDJLqrhrYK/qqsLRr34y8s1ayZVrinroNwx7prykDYBTSY1UIO22nNIYTlLCNW8H9ibFwm4naQ6p6cVOHZz7WVJy3/bAU3m8t0TEDWWN18xGjyfLXZL0FeDyiLivx/MvBH4cEdfnx/uSQjkWAedExM4DG+zYNSvvGtiruqtw9KrPjPw/As4DNs7byNsAB0TunGhmrUnaB/gSqcTkUlJjoyMi4qYOzv08aYJ8b0S8WeY4zZrJu5JnSTqXVfOZABjG7+mpyJPlikm6f3zMYVFKp9MKFT1c82Gq7xrYl7qqcNRB0s3AicD5DdVKHoiIreodmVl38o3f51l9F6tlt9ABXffdpA6lAn4ebshgI0LSxyPiGkmHN3s+ItyYagg4Zrl6z+Ykth/lxwuA53L5ordbn9aXyrsGDsBIte+UNI3UOGVlBz/S5LeT2PB3RsRd48Isvcplo2gx8G3gO4ztYlVhD1LoRwDTgCsrvLZZzyLimvzH1yJiceNzkg5ucorVwCvLFcsTvpMZi+m7jRTj9zKp9NFjA7zWNaQvj+lU3DVwkKpqLNIPSd8hfUkXqwCHAm9FxNEdnLsE+CypDOF2kuYDR0XEvNIGbFYCSfdGxPYVX/NbpHbKRafDBcDjEXFMleMw60eLBi5DXQlqKvFkeRLLyXICFgKNveMFLCwjPnqq6qdklqRNGatF+xLwJHCIi9HbqJF0CqlS0JWsemNeWqKrpEeALYows1zK8cGI2KKsa5oNiqR5wMdIhQMub3hqBil8csJEVSufwzAqJmkmaeL6IWDt4ngZMX2RW2hLmhbj2mlLWmfQ15vi3pI0JyIeh5UT4Lbb0OPqLF8H3AisQaqmcRDgOss2aoq4yxMbjgWpk1tZHgM2AYqby1n5mNkoeAa4BziAVC+8sBz4XC0jstV4sly9S0l3j/uTWqseDrxQxoUaW47mdsyF6aTwDxucE4EbJT1BWrn/fWCiznxFneUPksrkXZXPPZQUMmM2UiJidg2XnQ48LOku0sR8J1Kuw9V5TCMRbmZTUw4x/KWky8rst2D9cRhGxYqYvqICRj52d0TsONG5PVxrPWAD3HK0EpLWIk18ITV++V271zec9zNgv4hYnh9PB66NiN3bn2k2fKqu6Z7DzVoav6tmNowk/TFwCmmhZU3SwklH5UetfF5Zrl5x5/ispP1IWzDNuvr1LSJeJiUOfqKM97fVbM/YJOHDkjqdJGwMvN7w+PV8zGyktKrpDpTZAOmF8c1aJM3tpM6y2RC5iBR2cS/VVpKxDniyXL3T8orvCcC5pCB+xyWNuD4nCZcAd0kqyl0dSGrIYjZqdqD6mu5XSLoE+CopD+SsPI6PVDgGs369HBFL6h6ENecwDLMB6Lfxi6TtSG13AX4WEcsGNjizikhaDPxNRFRW013SuqSKP9uT4pcvJVX7KatuvdnASToTeAfw76xaSeYXtQ3KVvLKcsUkzQaOZfWYPiehjLa+Gr/kD0R/KNqo2wh4KCfbVVXT/Q1gBbAOaWX5SU+UbQQVpVx3aDgWQKndL60zXlmuWG7jfBFwPw0d+5yEMpomS+MXs0FolWxX5udb/ky9CvgyMJPUQfD1iHD3MzMbCE+WKybpTjcDmTzc+MWsXpJ2IlWhmR0RX5a0CXBYRJxW89DMOiZpY+AM4PciYp6kLYGPRMRFNQ/N8GS5cpI+CWwGLMVxSZNGi1alK8sDmk1mkm6NiF0lLSfttKx8ilT+akaJ1z6PtEu3V0RsIWkDYGkZ5TjNyiJpCbAI+MeI2FbSmsCyiNi65qEZjlmuw9akphN7MRaG4bikEeXGL2YQEbvm39Mnem0Jdo6I7SQty2N4SdK0GsZh1o+NIuIKSV8EiIg3JbmE3JDwZLl6BwObRsTrE77SRsFlwBLc+MWsLm9Iegd5RVvSTFZd3TYbBa9Kejdj/453IfVJsCHgyXL1HgDWB56veyDWPzd+MavdN4ArgfdIOh2YD3yp3iGZde144GpgjqTbSMmq8+sdkhU8Wa7e+sAjku7GVRPMzPoSEZdKuhfYmxQjfWBEPFzzsMy6NQeYB8wCDiKVkvMcbUg4wa9idZRWMjMzs+FVJIRL2hX4Z+BrwD+5otJw8F1LxTwpNjMzs3GKZL79gAsj4lpJLn84JNaoewBThaRb8+/lkl5p+Fku6ZW6x2dmZma1+bWk84EFwHWS1sJztKHhMAwzMzOzGkl6J/AnwP0R8aik9wFbR8TSmodmeLJsZmZmZtaSl/jNzMzMzFrwZNnMzMzMrAVPls3MhoikpyRFk5+nWrz+pvz8RhUP1cxsSnDpODOz4XIssC6wP3AI8G3gZuDVOgdlZjZVeWXZzGyIRMQ1EfEj4L586E7geuAgSS/kn0skbTD+XElH5lXmi5V8UdKTuUTl9ZI2za87Jb/uQkmP5vc8uLq/pZnZ6PBk2cxs+J0DHA58F1gEHJqPNdofuAD4IXA0cBhwBmmyfSawDbB43Dm7Af8KrJdfY2Zm4zgMw8xs+H0M+HVEnAgg6ZPAvHGvuZAUrnFYRLwtaf98fEH+AXivpA0bzjk7Ii6Q9Glgs/KGb2Y2ujxZNjObHJ4HdgA2Bx5oOH5Ifg7SbuJrDc/9Nv9+E+80mpk15Q9HM7Phdy3wfkkLJS0E3g9cN+4184G3gCWSPgD8JB8/HJgF7AGcFBH/V9GYzcwmBa8sm5kNv+Py76Py7+83HCs8Cvw5sJQ0kd4N+Hvgr4HzgKeBy0sfqZnZJON212ZmZmZmLTgMw8zMzMysBU+WzczMzMxa8GTZzMzMzKwFT5bNzMzMzFrwZNnMzMzMrAVPls3MzMzMWvBk2czMzMysBU+WzczMzMxa+H+tN5hylHJOfgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQaDYviO9uPL",
        "colab_type": "text"
      },
      "source": [
        "### Compare for classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anZ5C5aZ983m",
        "colab_type": "text"
      },
      "source": [
        "Attributions assigned to tokens may take opposite values when computed with regard to class 0 and class 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2F68D3s9v0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "cbc44b45-c4c3-4469-ef72-c7244442f6e5"
      },
      "source": [
        "# word_embeddings: index 0\n",
        "lig_0 = layer_attributions_0[0].squeeze().sum(1)\n",
        "lig_1 = layer_attributions_1[0].squeeze().sum(1)\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenizer(text)[\"input_ids\"])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
        "plt.bar(list(range(len(lig_0))), lig_0, color='r', alpha=0.5)\n",
        "plt.bar(list(range(len(lig_1))), lig_1, color='g', alpha=0.5)\n",
        "plt.xticks(list(range(len(lig_0))), tokens, rotation='vertical')\n",
        "plt.legend(labels=[\"Target: negative\", \"Target: positive\"])\n",
        "plt.xlabel('Token', fontweight='bold')\n",
        "plt.title(\"Token attributions for positive and negative target class\")\n",
        "plt.show()"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP_Wa1S_-RmC",
        "colab_type": "text"
      },
      "source": [
        "Compare IG and LIG attributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9WIp8XJXrZc",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tryuEZ0LbNNO",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eNIcNg4-aFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_data(text):\n",
        "    input_data = place_on_device(*prepare_input(text))\n",
        "    input_data_embed = prepare_input_embed(*input_data)   \n",
        "    return input_data, input_data_embed \n",
        "\n",
        "\n",
        "def ig_attribute(class_index, input_data_embed):\n",
        "    return ig.attribute(inputs=input_data_embed[0:3],\n",
        "                        baselines=input_data_embed[3:6],\n",
        "                        additional_forward_args=(input_data_embed[6]),\n",
        "                        target = class_index,\n",
        "                        return_convergence_delta=True,\n",
        "                        n_steps=200)\n",
        "    \n",
        "\n",
        "def lig_attribute(class_index, input_data):\n",
        "    return lig.attribute(\n",
        "        inputs=input_data[0], baselines=input_data[3],\n",
        "        additional_forward_args=(input_data[1], input_data[2], input_data[6]),\n",
        "        return_convergence_delta=True, target=class_index)\n",
        "\n",
        "\n",
        "def summarize_attributions(attributions):\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    return attributions\n",
        "\n",
        "\n",
        "def compute_attributions_ig(input_data_embed):\n",
        "    # Create interpretable layer\n",
        "    if not type(\n",
        "        model.get_input_embeddings()).__name__ == \"InterpretableEmbeddingBase\":    \n",
        "        interpretable_embedding1, interpretable_embedding2,\\\n",
        "        interpretable_embedding3 = configure_interpretable_embeddings()\n",
        "    # Compute attributions for positive and nagative samples (class 1 and 0)\n",
        "    attr_0, delta_0 = ig_attribute(0, input_data_embed)\n",
        "    attr_1, delta_1 = ig_attribute(1, input_data_embed)\n",
        "    # Remove interprateble layer used by ig attribution\n",
        "    remove_interpretable_embeddings(interpretable_embedding1, \n",
        "                                    interpretable_embedding2, \n",
        "                                    interpretable_embedding3)\n",
        "    # Return attributions for 'input_ids' (element 0) for 0 and 1 class indices\n",
        "    return (attr_0[0], delta_0), (attr_1[0], delta_1)    \n",
        "\n",
        "\n",
        "def compute_attributions_lig(input_data):  \n",
        "    # Compute attributions for positive and nagative samples (class 1 and 0)\n",
        "    return lig_attribute(0, input_data), lig_attribute(1, input_data)\n",
        "\n",
        "\n",
        "def get_visualization_record(text, attributions, scores, true_label,\n",
        "                             all_tokens, approximation_error):\n",
        "    attributions_sum = summarize_attributions(attributions)\n",
        "    return viz.VisualizationDataRecord(\n",
        "        attributions_sum,\n",
        "        torch.max(torch.softmax(scores[0], dim=0)),\n",
        "        torch.argmax(scores),\n",
        "        true_label,\n",
        "        text,\n",
        "        attributions_sum.sum(),\n",
        "        all_tokens,\n",
        "        approximation_error)\n",
        "    \n",
        "\n",
        "def visualize_attributions(text, true_label, method):\n",
        "    # Prepare input\n",
        "    input_data = place_on_device(*prepare_input(text))\n",
        "    input_data_embed = prepare_input_embed(*input_data)\n",
        "    # Compute attributions\n",
        "    attr_0, attr_1, delta_0, delta_1 = None, None, None, None\n",
        "    if method == \"ig\":\n",
        "        (attr_0, delta_0), (attr_1, delta_1) = \\\n",
        "        compute_attributions_ig(input_data_embed)\n",
        "    elif method == \"lig\":    \n",
        "        (attr_0, delta_0), (attr_1, delta_1) = \\\n",
        "        compute_attributions_lig(input_data)\n",
        "    else:\n",
        "        return \"method: ig or lig\"    \n",
        "    # Run inference\n",
        "    scores = predict_forward_func(*input_data[0:3], input_data[-1])\n",
        "    # Prepare visualization \n",
        "    indices = input_data[0][0].detach().tolist()\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
        "    data_vis_0 = get_visualization_record(text, attr_0, scores, \n",
        "                                          true_label, all_tokens, delta_0)  \n",
        "    data_vis_1 = get_visualization_record(text, attr_1, scores, \n",
        "                                          true_label, all_tokens, delta_1) \n",
        "    # Visualize\n",
        "    print(\"\\nAttribution method: {},\".\n",
        "          format(method), \"class index: 0 (negative)\")\n",
        "    viz.visualize_text([data_vis_0])\n",
        "    print(\"Attribution method: {},\".\n",
        "          format(method), \"Class index: 1 (positive)\")\n",
        "    viz.visualize_text([data_vis_1]) \n",
        "    return attr_0, attr_1    "
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8m9IAb2Z-vn",
        "colab_type": "text"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGn3780AmD_Z",
        "colab_type": "text"
      },
      "source": [
        "Captum visualization library shows in green tokens that push the prediction towards the target class. Those driving the score towards the reference value are marked in red. As a result, words perceived as positive will appear in green if attribution is performed against class 1 (positive) but will be highlighted in red with an attribution targeting class 0 (negative).\n",
        "\n",
        "Because importance scores ar assigned to tokens, not words, some examples may show that attribution is highly dependent on tokenization. Classification result may vary between runs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHyNJIc39rUr",
        "colab_type": "text"
      },
      "source": [
        "Browse examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka-dgLIEgYPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "6e6a82f7e38145529a64db841bbca7af",
            "cbd634f3fbd74387a04056c00b756fc4",
            "3b058709915540e0ae1fa23dbb5d35b6",
            "851bafaffba1473180428eefdd559077",
            "4dbe2849168d446e99e68413c2e2d8f8",
            "a70ad77b79234d67b54326be02bf7e25",
            "7dc281ce77b94480a4977f196b014309",
            "5fb48980e51546c98aa34d51f496e4b1"
          ]
        },
        "outputId": "15e913fe-5ee0-4658-f75d-df0a35e9b283"
      },
      "source": [
        "# Run predictions\n",
        "eval_pred_result = trainer.predict(eval_dataset)\n",
        "predictions = np.argmax(eval_pred_result.predictions, axis=1)\n",
        "\n",
        "# Find misclassifed samples\n",
        "eval_samples = [tokenizer.decode(x.input_ids, skip_special_tokens=True) \\\n",
        "                for x in eval_dataset]\n",
        "eval_preds = list(zip(eval_pred_result.label_ids, predictions))\n",
        "positive_pred_as_positive = [sample for sample, (real_label, pred_label) \\\n",
        "                             in zip(eval_samples, eval_preds) \\\n",
        "                             if real_label == pred_label and real_label == 1]  \n",
        "negative_pred_as_negative = [sample for sample, (real_label, pred_label) \\\n",
        "                             in zip(eval_samples, eval_preds) \\\n",
        "                             if real_label == pred_label and real_label == 0]                               \n",
        "negative_pred_as_positive = [sample for sample, (real_label, pred_label) \\\n",
        "                             in zip(eval_samples, eval_preds) \\\n",
        "                             if real_label != pred_label and real_label == 0]\n",
        "positive_pred_as_negative = [sample for sample, (real_label, pred_label) \\\n",
        "                             in zip(eval_samples, eval_preds) \\\n",
        "                             if real_label != pred_label and real_label == 1]\n",
        "\n",
        "# Browse\n",
        "# print('\\n'.join(positive_pred_as_positive))   \n",
        "# print('\\n'.join(negative_pred_as_negative))    \n",
        "# print('\\n'.join(negative_pred_as_positive))     \n",
        "# print('\\n'.join(positive_pred_as_negative))                                          "
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e6a82f7e38145529a64db841bbca7af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=109.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6FcN8liZyda",
        "colab_type": "text"
      },
      "source": [
        "#### Positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHHxBoJ7oMOM",
        "colab_type": "text"
      },
      "source": [
        "A correctly classified positive sample\n",
        "\n",
        "Use our example or pick your own by setting *text_vis* and *true_label_vis* variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGrav0a8oecG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "59514359-b378-4cfb-9b5e-6faeb0c321c6"
      },
      "source": [
        "text_vis = text\n",
        "true_label_vis = true_label\n",
        "\n",
        "ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n",
        "# lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
            "  \"In order to make embedding layers more interpretable they will \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Attribution method: ig, class index: 0 (negative)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . </b></text></td><td><text style=\"padding-right:2em\"><b>-3.63</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> imaginative                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thematic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ally                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ins                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##truct                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ive                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thoroughly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> delightful                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roller                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coaster                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ride                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innocence                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experience                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> without                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hint                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typical                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kidd                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flick                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sentimental                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ity                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Attribution method: ig, Class index: 1 (positive)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality . </b></text></td><td><text style=\"padding-right:2em\"><b>3.64</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> imaginative                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thematic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ally                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ins                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##truct                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ive                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thoroughly                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> delightful                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> takes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> roller                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coaster                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ride                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> from                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innocence                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> experience                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> without                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hint                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> typical                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> kidd                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> flick                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sentimental                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ity                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJUKqnKJaBDo",
        "colab_type": "text"
      },
      "source": [
        "#### Negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVf89iWsECJp",
        "colab_type": "text"
      },
      "source": [
        "A correctly classified negative sample\n",
        "\n",
        "Use the example below or pick your own by setting text_vis and true_label_vis variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku4Jq-9zf-K8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f856c45d-51d8-4cf9-80bd-525cdc3b5818"
      },
      "source": [
        "text_vis = 'the film makes a fatal mistake : it asks us to care about a young \\\n",
        "man whose only apparent virtue is that he is not quite as unpleasant as some \\\n",
        "of the people in his life.'\n",
        "true_label_vis = 0\n",
        "\n",
        "ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n",
        "# lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
            "  \"In order to make embedding layers more interpretable they will \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Attribution method: ig, class index: 0 (negative)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>the film makes a fatal mistake : it asks us to care about a young man whose only apparent virtue is that he is not quite as unpleasant as some of the people in his life.</b></text></td><td><text style=\"padding-right:2em\"><b>3.66</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> makes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fatal                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mistake                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asks                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> man                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> virtue                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quite                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unpleasant                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Attribution method: ig, Class index: 1 (positive)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>the film makes a fatal mistake : it asks us to care about a young man whose only apparent virtue is that he is not quite as unpleasant as some of the people in his life.</b></text></td><td><text style=\"padding-right:2em\"><b>-3.62</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> makes                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fatal                    </font></mark><mark style=\"background-color: hsl(0, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mistake                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> asks                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> us                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> care                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> young                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> man                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whose                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> apparent                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> virtue                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> he                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> quite                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unpleasant                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> some                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> people                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> his                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> life                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzZhcUMKn3My",
        "colab_type": "text"
      },
      "source": [
        "#### Misclassified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCHm7T-ih-zZ",
        "colab_type": "text"
      },
      "source": [
        "Negative examples misclassified as positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8sGOEfHNtQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "315f8b61-d308-4abf-bce4-05e48c28614a"
      },
      "source": [
        "print('\\n'.join(negative_pred_as_positive)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the title not only describes its main characters, but the lazy people behind the camera as well.\n",
            "the script kicks in, and mr. hartley's distended pace and foot - dragging rhythms follow.\n",
            "it's one pussy - ass world when even killer - thrillers revolve around group therapy sessions.\n",
            "you won't like roger, but you will quickly recognize him.\n",
            "this riveting world war ii moral suspense story deals with the shadow side of american culture : racial prejudice in its ugly and diverse forms.\n",
            "sam mendes has become valedictorian at the school for soft landings and easy ways out.\n",
            "every nanosecond of the the new guy reminds you that you could be doing something else far more pleasurable.\n",
            "it seems to me the film is about the art of ripping people off without ever letting them consciously know you have done so\n",
            "confirms the nagging suspicion that ethan hawke would be even worse behind the camera than he is in front of it.\n",
            "by getting myself wrapped up in the visuals and eccentricities of many of the characters, i found myself confused when it came time to get to the heart of the movie.\n",
            "delivers the same old same old, tarted up with latin flava and turned out by hollywood playas.\n",
            "it's hard to like a film about a guy who is utterly unlikeable, and shiner, starring michael caine as an aging british boxing promoter desperate for a taste of fame and fortune, is certainly that.\n",
            "the x potion gives the quickly named blossom, bubbles and buttercup supernatural powers that include extraordinary strength and laser - beam eyes, which unfortunately don't enable them to discern flimsy screenplays.\n",
            "i'll bet the video game is a lot more fun than the film.\n",
            "if director michael dowse only superficially understands his characters, he doesn't hold them in contempt.\n",
            "i don't mind having my heartstrings pulled, but don't treat me like a fool.\n",
            "oh come on.\n",
            "a tv style murder mystery with a few big screen moments ( including one that seems to be made for a different film altogether ).\n",
            "a by - the - numbers patient / doctor pic that covers all the usual ground\n",
            "it showcases carvey's talent for voices, but not nearly enough and not without taxing every drop of one's patience to get to the good stuff.\n",
            "moretti's compelling anatomy of grief and the difficult process of adapting to loss.\n",
            "although huppert's intensity and focus has a raw exhilaration about it, the piano teacher is anything but fun.\n",
            "every dance becomes about seduction, where backstabbing and betrayals are celebrated, and sex is currency.\n",
            "it takes a certain kind of horror movie to qualify as ` worse than expected,'but ghost ship somehow manages to do exactly that.\n",
            "vera's technical prowess ends up selling his film short ; he smoothes over hard truths even as he uncovers them.\n",
            "davis... is so enamored of her own creation that she can't see how insufferable the character is.\n",
            "without non - stop techno or the existential overtones of a kieslowski morality tale, maelstrom is just another winter sleepers.\n",
            "the longer the movie goes, the worse it gets, but it's actually pretty good in the first few minutes.\n",
            "sit through this one, and you won't need a magic watch to stop time ; your dvd player will do it for you.\n",
            "it's everything you don't go to the movies for.\n",
            "the man from elysian fields is a cold, bliss - less work that groans along thinking itself some important comment on how life throws us some beguiling curves.\n",
            "american chai encourages rueful laughter at stereotypes only an indian - american would recognize.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkAmTeq6u3oI",
        "colab_type": "text"
      },
      "source": [
        "Pick an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9GoAAQROGDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text_vis = \"...\"\n",
        "#true_label_vis = 0\n",
        "\n",
        "#ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n",
        "#lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTNNTfVdiEXk",
        "colab_type": "text"
      },
      "source": [
        "Positive examples misclassified as negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9f9G-gdN1_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "362f27d2-16dc-48db-f9b5-2297347a8cb6"
      },
      "source": [
        "print('\\n'.join(positive_pred_as_negative)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we root for ( clara and paul ), even like them, though perhaps it's an emotion closer to pity.\n",
            "if steven soderbergh's ` solaris'is a failure it is a glorious failure.\n",
            "a full world has been presented onscreen, not some series of carefully structured plot points building to a pat resolution.\n",
            "a coda in every sense, the pinochet case splits time between a minute - by - minute account of the british court's extradition chess game and the regime's talking - head survivors.\n",
            "as unseemly as its title suggests.\n",
            "while there's something intrinsically funny about sir anthony hopkins saying ` get in the car, bitch,'this jerry bruckheimer production has little else to offer\n",
            "( d ) oesn't bother being as cloying or preachy as equivalent evangelical christian movies - - maybe the filmmakers know that the likely audience will already be among the faithful.\n",
            "we haven't seen such hilarity since say it isn't so!\n",
            "something akin to a japanese alice through the looking glass, except that it seems to take itself far more seriously.\n",
            "intriguing documentary which is emotionally diluted by focusing on the story's least interesting subject.\n",
            "harrison's flowers puts its heart in the right place, but its brains are in no particular place at all.\n",
            "on the heels of the ring comes a similarly morose and humorless horror movie that, although flawed, is to be commended for its straight - ahead approach to creepiness.\n",
            "another one of those estrogen overdose movies like ` ` divine secrets of the ya ya sisterhood,'' except that the writing, acting and character development are a lot better.\n",
            "this flick is about as cool and crowd - pleasing as a documentary can get.\n",
            "still, as a visual treat, the film is almost unsurpassed.\n",
            "the jabs it employs are short, carefully placed and dead - center.\n",
            "drops you into a dizzying, volatile, pressure - cooker of a situation that quickly snowballs out of control, while focusing on the what much more than the why.\n",
            "a study in shades of gray, offering itself up in subtle plot maneuvers...\n",
            "no screen fantasy - adventure in recent memory has the showmanship of clones'last 45 minutes.\n",
            "... routine, harmless diversion and little else.\n",
            "but it still jingles in the pocket.\n",
            "writer / director joe carnahan's grimy crime drama is a manual of precinct cliches, but it moves fast enough to cover its clunky dialogue and lapses in logic.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiLOTdTGu2Kf",
        "colab_type": "text"
      },
      "source": [
        "Pick an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyKdJ2sEV0OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text_vis = \"...\"\n",
        "#true_label_vis = 1\n",
        "\n",
        "#ig_0, ig_1 = visualize_attributions(text_vis, true_label_vis, \"ig\")\n",
        "# lig_0, lig_1 = visualize_attributions(text_vis, true_label_vis, \"lig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D23Ejoku1P4b",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6GWu4mq1URt",
        "colab_type": "text"
      },
      "source": [
        "https://captum.ai/tutorials/Bert_SQUAD_Interpret\n",
        "\n",
        "https://captum.ai/docs/algorithms\n",
        "\n",
        "https://captum.ai/api/integrated_gradients.html\n",
        "\n",
        "https://github.com/google-research/electra/\n",
        "\n",
        "https://github.com/google-research/electra/blob/master/configure_finetuning.py\n",
        "\n",
        "https://github.com/huggingface/nlp/blob/master/notebooks/Overview.ipynb\n",
        "\n",
        "https://huggingface.co/transformers/main_classes/trainer.html"
      ]
    }
  ]
}